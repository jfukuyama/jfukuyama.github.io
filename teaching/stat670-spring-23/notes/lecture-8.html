<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Julia Fukuyama" />
  <title>Stat 470/670 Lecture 8: Flexible modeling for bivariate data</title>
  <style type="text/css">
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="https://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <script src="https://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Stat 470/670 Lecture 8: Flexible modeling for
bivariate data</h1>
  <p class="author">
Julia Fukuyama
  </p>
</div>
<div id="today" class="slide section level2">
<h1>Today</h1>
<ul>
<li>Review linear regression/parametric smoothers</li>
</ul>
<ul>
<li>Nonparametric smoothers</li>
</ul>
</div>
<div id="regression-review" class="slide section level2">
<h1>Regression review</h1>
<p>Task 1: How do we use multiple regression to fit non-linear functions
of predictors?</p>
<p>Task 2: How can we use weights in regression to do local fits?</p>
</div>
<div
id="transformations-of-the-predictor-variables-polynomial-regression"
class="slide section level2">
<h1>Transformations of the predictor variables: Polynomial
regression</h1>
<p>One example of multiple regression to fit a non-linear mean, where we
use as predictors carat plus the second and third powers of carat.</p>
<p>This gives us the best-fitting third-degree polynomial.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>diamonds <span class="ot">=</span> diamonds <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">log_price =</span> <span class="fu">log10</span>(price))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>lm.poly <span class="ot">=</span> <span class="fu">lm</span>(</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    log_price <span class="sc">~</span> carat <span class="sc">+</span> <span class="fu">I</span>(carat<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(carat<span class="sc">^</span><span class="dv">3</span>),</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> diamonds, <span class="at">subset =</span> clarity <span class="sc">==</span> <span class="st">&quot;VS1&quot;</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">augment</span>(lm.poly)) <span class="sc">+</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> carat, <span class="at">y =</span> log_price), <span class="at">size =</span> .<span class="dv">5</span>, <span class="at">alpha =</span> .<span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> carat, <span class="at">y =</span> .fitted), <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="lecture-8-fig/unnamed-chunk-1-1.png" /></p>
</div>
<div
id="transformations-of-the-predictor-variables-non-smooth-functions-of-the-predictors"
class="slide section level2">
<h1>Transformations of the predictor variables: Non-smooth functions of
the predictors</h1>
<p>Here we augment our initial predictors with several step functions of
the predictors:</p>
<p><span class="math display">\[
f_a(x) = \begin{cases}
1 &amp; x \ge a\\
0 &amp; x &lt; a
\end{cases}
\]</span></p>
<div class="incremental">
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>step <span class="ot">=</span> <span class="cf">function</span>(x, step_position) {</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">ifelse</span>(x <span class="sc">&gt;=</span> step_position, <span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>lm.steps <span class="ot">=</span> <span class="fu">lm</span>(</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    log_price <span class="sc">~</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        carat <span class="sc">+</span> <span class="fu">I</span>(carat<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(carat<span class="sc">^</span><span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="fu">step</span>(carat, .<span class="dv">3</span>) <span class="sc">+</span> <span class="fu">step</span>(carat, .<span class="dv">5</span>) <span class="sc">+</span> <span class="fu">step</span>(carat, <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">step</span>(carat, <span class="fl">1.5</span>) <span class="sc">+</span> <span class="fu">step</span>(carat, <span class="dv">2</span>),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> diamonds, <span class="at">subset =</span> clarity <span class="sc">==</span> <span class="st">&quot;VS1&quot;</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">augment</span>(lm.steps)) <span class="sc">+</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> carat, <span class="at">y =</span> log_price), <span class="at">size =</span> .<span class="dv">5</span>, <span class="at">alpha =</span> .<span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> carat, <span class="at">y =</span> .fitted), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="lecture-8-fig/unnamed-chunk-2-1.png" /></p>
</div>
</div>
<div
id="transformations-of-the-predictor-variables-dummy-variables-for-factors"
class="slide section level2">
<h1>Transformations of the predictor variables: Dummy variables for
factors</h1>
<p>The dummy or indicator function, <span class="math inline">\(\mathbf
I_a\)</span> can be used to transform factor variables into numeric
predictors:</p>
<p><span class="math display">\[
\mathbf I_a(x) = \begin{cases}
1 &amp; x = a \\
0 &amp; x \ne a
\end{cases}
\]</span></p>
<div class="incremental">
<p>This is what R is doing behind the scenes when you use a factor
variable in a linear model.</p>
<p>We can inspect the transformation it uses with
<code>model.matrix</code>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">model.matrix</span>(<span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> color, <span class="at">data =</span> diamonds))</span></code></pre></div>
<pre><code>##   colorD colorE colorF colorG colorH colorI colorJ
## 1      0      1      0      0      0      0      0
## 2      0      1      0      0      0      0      0
## 3      0      1      0      0      0      0      0
## 4      0      0      0      0      0      1      0
## 5      0      0      0      0      0      0      1
## 6      0      0      0      0      0      0      1</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(diamonds<span class="sc">$</span>color)</span></code></pre></div>
<pre><code>## [1] E E E I J J
## Levels: D &lt; E &lt; F &lt; G &lt; H &lt; I &lt; J</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(price <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> color, <span class="at">data =</span> diamonds)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = price ~ 0 + color, data = diamonds)
## 
## Coefficients:
## colorD  colorE  colorF  colorG  colorH  colorI  colorJ  
##   3170    3077    3725    3999    4487    5092    5324</code></pre>
</div>
</div>
<div
id="generalizations-of-the-regression-problem-weighted-least-squares"
class="slide section level2">
<h1>Generalizations of the regression problem: Weighted least
squares</h1>
<p>If we have more faith in some points than others, or if we simply
want to exclude some points, we can perform weighted linear
regression.</p>
<p>Let <span class="math inline">\(w_i\)</span>, <span
class="math inline">\(i = 1,\ldots, n\)</span> be non-negative
values.</p>
<p>In weighted regression, we find <span class="math inline">\(\beta_0,
\ldots, \beta_p\)</span> to minimize</p>
<p><span class="math display">\[
\sum_{i=1}^n w_i (y_i - (\beta_0 + \beta_1 x_{i1} + \cdots + \beta_p
x_{ip}))^2
\]</span></p>
<p>Or, in matrix notation: <span class="math display">\[
\|\mathbf W^{1/2} (\mathbf y - \mathbf X \mathbf \beta)\|_2^2
\]</span> where <span class="math inline">\(\mathbf W^{1/2}\)</span> is
an <span class="math inline">\(n \times n\)</span> diagonal matrix with
<span class="math inline">\(w_i^{1/2}\)</span> as the <span
class="math inline">\(i\)</span>th diagonal element.</p>
<div class="incremental">
<p>Properties:</p>
<ul class="incremental">
<li><p>Setting <span class="math inline">\(w_i = 0\)</span> is
equivalent to omitting the <span class="math inline">\(i\)</span>th data
point from the analysis.</p></li>
<li><p>Setting all of the <span class="math inline">\(w_i\)</span>’s
equal to <span class="math inline">\(1\)</span>, or all the equal to the
same positive value, leads to the same coefficient estimates as standard
linear regression.</p></li>
<li><p>Heuristically, points with higher values of <span
class="math inline">\(w_i\)</span> have higher “weight” in the
regression estimation: the line is penalized more for deviating from
those points, and so the fitted line will tend to track points with high
weights more closely than points with low weights.</p></li>
</ul>
</div>
</div>
<div id="references" class="slide section level2">
<h1>References</h1>
<p>If you feel like you need to brush up on this, a good reference is
Weisberg, Applied Linear Regression.</p>
<ul>
<li>Section 3.4 of Weisberg describes the matrix notation version of
multiple regression.</li>
</ul>
<ul>
<li>Chapter 6 of Weisberg describes polynomial regression and indicator
matrices for factor variables.</li>
</ul>
</div>
<div id="smoothing" class="slide section level2">
<h1>Smoothing</h1>
<p>Reading: Cleveland pp. 91-110</p>
<p>Why do we want to smooth?</p>
<ul class="incremental">
<li><p>If we have a lot of data/noise, the smoother allows us to see
what we can’t in a scatterplot of the raw data.</p></li>
<li><p>If we want to compare multiple sets of points, the smoother
simplifies the description and allows us to make the comparison between
the “main effects” in the data without our eye being distracted by the
noise.</p></li>
<li><p>Non-EDA: If we want to predict or estimate true underlying values
from noisy data, smoothers often help. Remember though, if this is your
purpose, you should still do the exploratory analysis to decide what
type of smoother to use, whether there should be breaks or jumps in the
smoother, or if any other weird things are happening.</p></li>
</ul>
</div>
<div id="loess" class="slide section level2">
<h1>LOESS</h1>
<p>LOESS, or local regression, builds on standard regression. The setup
is:</p>
<ul>
<li>We have bivariate data, so pairs <span class="math inline">\((y_i,
x_i)\)</span>, <span class="math inline">\(i = 1,\ldots,
n\)</span>.</li>
</ul>
<ul>
<li>We want to estimate the mean <span class="math inline">\(E(Y \mid
X)\)</span>. We think this is a smooth function of <span
class="math inline">\(X\)</span>, but we don’t know what the form of
that function is.</li>
</ul>
<p>The idea is that since the mean function is smooth, it can be
approximated with a linear or low-order polynomial function in small
regions.</p>
</div>
<div id="loess-details" class="slide section level2">
<h1>LOESS: details</h1>
<p>The way we transform this intuition into a concrete procedure is to
use weighted least squares.</p>
<p>LOESS has two parameters, <span class="math inline">\(\alpha\)</span>
(the span), and <span class="math inline">\(\lambda\)</span>, the degree
of the local polynomial.</p>
<p>To find the value of the LOESS smoother at a point <span
class="math inline">\(x_0\)</span>, we first define weights for all of
the samples: <span class="math display">\[
w_i(x_0) = T(\Delta_i(x_0) / \Delta_{(q)}(x_0))
\]</span> where <span class="math inline">\(\Delta_i(x_0) = |x_i -
x_0|\)</span>, <span class="math inline">\(\Delta_{(i)}(x_0)\)</span>
are the ordered values of <span
class="math inline">\(\Delta_{i}(x_0)\)</span>, and <span
class="math inline">\(q = \alpha n\)</span>, rounded to the nearest
integer.</p>
<p><span class="math inline">\(T\)</span> is the tricube weight function
(invented by Tukey!): <span class="math display">\[
T(u) = \begin{cases}
(1 - |u|^3)^3 &amp; |u| \le 1 \\
0 &amp; |u| &gt; 1
\end{cases}
\]</span></p>
<p><img src="lecture-8-fig/unnamed-chunk-4-1.png" /></p>
</div>
<div class="slide section level2">

<p>These weights are then used in a local regression.</p>
<p>If <span class="math inline">\(\lambda = 1\)</span>, we find <span
class="math inline">\(\hat \beta_0\)</span>, <span
class="math inline">\(\hat \beta_1\)</span> to minimize the weighted
least squares criterion, <span class="math display">\[
\sum_{i=1}^n w_i (y_i - (\beta_0 + \beta_1 x_i))^2,
\]</span></p>
<p>and the fitted value for the LOESS smoother at <span
class="math inline">\(x_0\)</span> is <span class="math inline">\(\hat
\beta_0 + \hat \beta_1 x_0\)</span>.</p>
<div class="incremental">
<p>If <span class="math inline">\(\lambda = 2\)</span>, we use quadratic
regression, e.g. find <span class="math inline">\(\hat \beta_0\)</span>,
<span class="math inline">\(\hat \beta_1\)</span>, <span
class="math inline">\(\hat \beta_2\)</span> to minimize the weighted
least squares criterion, <span class="math display">\[
\sum_{i=1}^n w_i (y_i - (\beta_0 + \beta_1 x_i + \beta_2 x_i^2))^2,
\]</span></p>
<p>and the fitted value for the LOESS smoother at <span
class="math inline">\(x_0\)</span> is <span class="math inline">\(\hat
\beta_0 + \hat \beta_1 x_0 + \hat \beta_2 x_0^2\)</span>.</p>
</div>
<div class="incremental">
<p>The analogous procedure works for any integer value of <span
class="math inline">\(\lambda\)</span>.</p>
</div>
</div>
<div class="slide section level2">

<p>The procedure described above gives a fitted value of the smoother at
one point; and we need to do all the weight and coefficient computations
for every point at which we want to evaluate the smoother.</p>
</div>
<div id="loess-in-r" class="slide section level2">
<h1>LOESS in R</h1>
<p>We’ll look at the <code>economics</code> dataset (in ggplot2).</p>
<p>It looks like this:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>economics</span></code></pre></div>
<pre><code>## # A tibble: 574 × 7
##    date         pce    pop psavert uempmed unemploy date_numeric
##    &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;
##  1 1967-07-01  507. 198712    12.6     4.5     2944         -915
##  2 1967-08-01  510. 198911    12.6     4.7     2945         -884
##  3 1967-09-01  516. 199113    11.9     4.6     2958         -853
##  4 1967-10-01  512. 199311    12.9     4.9     3143         -823
##  5 1967-11-01  517. 199498    12.8     4.7     3066         -792
##  6 1967-12-01  525. 199657    11.8     4.8     3018         -762
##  7 1968-01-01  531. 199808    11.7     5.1     2878         -731
##  8 1968-02-01  534. 199920    12.3     4.5     3001         -700
##  9 1968-03-01  544. 200056    11.7     4.1     2877         -671
## 10 1968-04-01  544  200208    12.3     4.6     2709         -640
## # … with 564 more rows</code></pre>
</div>
<div class="slide section level2">

<p>Let’s look at how <code>psavert</code> changes over time using a
scatterplot:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(economics) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> date, <span class="at">y =</span> psavert))</span></code></pre></div>
<p><img src="lecture-8-fig/unnamed-chunk-6-1.png" /></p>
</div>
<div class="slide section level2">

<p>We’ll try smoothing here, but first note two tricky things about this
particular example:</p>
<ul class="incremental">
<li><p>The <code>loess</code> function doesn’t work well with
<code>date</code> class predictors, so we need to change date to
numeric.</p></li>
<li><p>When we plot the output, we want to plot the original date on the
x-axis, but <code>augment</code> by default only gives us the variables
that were used in the model (<code>date_numeric</code> and
<code>psavert</code>). To get a data frame with all the original
variables, we need to pass <code>augment</code> the extra argument
<code>data = economics</code>.</p></li>
</ul>
<div class="incremental">
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>economics <span class="ot">=</span> economics <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">date_numeric =</span> <span class="fu">as.numeric</span>(date))</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>l.out <span class="ot">=</span> <span class="fu">loess</span>(psavert <span class="sc">~</span> date_numeric, <span class="at">data =</span> economics)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">augment</span>(l.out, <span class="at">data =</span> economics), <span class="fu">aes</span>(<span class="at">x =</span> date, <span class="at">y =</span> .fitted)) <span class="sc">+</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> psavert)) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="lecture-8-fig/unnamed-chunk-7-1.png" /></p>
</div>
</div>
</body>
</html>
