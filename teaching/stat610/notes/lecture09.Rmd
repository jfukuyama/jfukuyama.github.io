## More on data manipulation, shape changing, merging, transformations

Reading: Hadley Wickham,
["Tidy Data"](http://vita.had.co.nz/papers/tidy-data.pdf)

Agenda for today:

- Reshaping/tidy data/wide vs. long format

- Merging

-----

## Tidy data

We usually want our data in the folowing form:

- In a rectangular data frame

- One row per observation

Data don't always come this way!

. . .

Even if the data do satisfy the "one row per observation" rule for one
analysis, they don't necessarily do so for another, and we often need
to change the "shape" of the data.

## Data semantics

Three concepts:

- Values

- Variables

- Observations

Datasets contain _values_, each of which belongs to a _variable_ and
an _observation_.


-----

Datasets can encode these in a lot of different ways. The "tidy" way
is to have

- Each variable a column

- Each observation a row

- Each cell a value

This is usually the way that other functions want the data to come in.

-----

For example:

![](treatment-wide.png)

What is easy to do with data in this format?

- See which treatment worked better for each individual.

- Run a paired t-test on treatment a vs. treatment b.

What is hard to do with data in this format?

- Run a linear model with result modeled as a function of treatment.

- Subset the data to the observations corresponding to a specific treatment (not hard so much as not programmatically nice).

-----

Same information:

![](treatment-long.png)

What is easy to do with data in this format?

- Run a linear model with result modeled as a function of treatment.

- Subset to observations corresponding to one treatment.

What is hard?

- Compute treatment a - treatment b.

- Run a paired t-test.

-----

Another example:

![](tb-wide.png)

Easy:

- See overall numbers of cases for each country.

- Compare some of the age ranges.


Hard:

- Plot cases as a function of sex, age, country, year.

- Model cases as a function of sex, age, country, year.

-----

![](tb-long.png)

Easy:

- Plot cases as a function of sex, age, country, year.

- Model cases as a function of sex, age, country, year.

Hard:

- Compute differences between number of cases in different categories (e.g. differences in cases between males and females holding all the other categories constant).

- See overall number of cases (not as compact as the other way).

-----

## General rules of thumb

- Columns are all special (accessed by name) and rows are not special (accessed programmatically).

- Easy to define functional relationships between variables (e.g. difference between two variables)/hard to define functional relationships between rows.

- Easy to subset rows/hard to subset columns.

- Easy to aggregate over rows/hard to aggregate over columns.

## Reshaping

The term for transforming these datasets into each other is called
"reshaping", and pretty much all reshaping can be done with a
combination of two operations: `pivot_longer` and `pivot_wider`.

These two functions do essentially what their names imply:

- `pivot_longer`: Takes a wide dataset and makes it long

- `pivot_wider`: Takes a long dataset and makes it wide.

You usually `pivot_longer` first to get the data into a tidy, long form, and then `pivot_wider` if you need a different layout for analysis or presentation.

## Pivoting longer

The `pivot_longer` function takes data from wide form to long form.

Syntax: `pivot_longer(data, cols)` or (usually) `data |> pivot_longer(cols)`

- `data` should be a data frame
- `cols` the columns to pivot into longer form. The values corresponding to these columns will all be put into one column in the output dataset. Can be a character vector or something more complicated that we will describe later.

What does the output look like?

- All the columns not listed in `cols` remain as identifier variables.
- One new column (called `name` by default) stores the former column names (the variable measured).
- Another new column (called `value` by default) stores the corresponding measurement values.



## Pivoting longer examples

Let's see an example. (Actually a very interesting study, can read [here](https://www.researchgate.net/publication/226555631_Frying_Performance_of_No-trans_Low-Linolenic_Acid_Soybean_Oils).)

```{r}
head(french_fries)
```

-----

We want to melt this data frame so that the "identification variables" are time, treatment, subject, rep and the "measurement variables" are the remainder: potato, buttery, grassy, rancid, painty.

```{r}
library(tidyr)

french_fries_long <- french_fries |>
  pivot_longer(cols = c("potato", "buttery", "grassy", "rancid", "painty"))

head(french_fries_long)
```

You can also specify columns using the column numbers (not recommended) or same syntax that [`select` uses](https://dplyr.tidyverse.org/reference/select.html) (much more useful).
The following are all equivalent:
```{r}
french_fries |>
    pivot_longer(cols = 5:9)
french_fries |>
    pivot_longer(cols = c(potato, buttery, grassy, rancid, painty))
french_fries |> pivot_longer(cols = potato:painty)
french_fries |>
    pivot_longer(cols = -c(time, treatment, subject, rep))
```

-----

You can make the output slightly nicer by specifying variable names
and value names with `names_to` and `values_to`:

```{r}
french_fries |>
    pivot_longer(cols = potato:painty,
                 names_to = "flavor", values_to = "flavor_intensity")
```

## Pivoting wider


Syntax: `pivot_wider(data, id_cols, names_from, values_from, values_fn)`

or, usually,

`data |> pivot_wider(id_cols, names_from, values_from, values_fn)`

- `data` should be a data frame.
- `id_cols` specifies the variables you want to use to define what the rows of the wide data frame should be.
- `names_from` specifies the variables you want to use to define what the columns of the wide data frame sholud be.
- `values_from` specifies what the elements of the wide data frame should be.
- `values_fn`: only used in some cases, discussed later.

-----

Example

. . .

```{r}
french_fries_long = french_fries |>
    pivot_longer(cols = potato:painty,
                 names_to = "flavor", values_to = "flavor_intensity")
french_fries_long |>
    head()
french_fries_long |>
    pivot_wider(id_cols = c(subject, rep, flavor),
                names_from = c(time, treatment),
                values_from = flavor_intensity) |>
    head()
french_fries_long |> subset(time == 1 & subject == "3" & rep == 1 & flavor == "potato")
```


----

If you don't specify `id_cols`, `pivot_wider` assumes that everything that is not specified in `names_from` and `values_from` should be used as `id_cols`.

```{r}
french_fries_long |>
    pivot_wider(id_cols = c(subject, rep, flavor),
                names_from = c(time, treatment),
                values_from = flavor_intensity) |>
    head()
french_fries_long |>
    pivot_wider(names_from = c(time, treatment),
                values_from = flavor_intensity) |>
    head()
```

## Aggregation

When you pivot wider, you don't necessarily use all of the variables.

This means that each element of the cast table will correspond to more
than one measurement, and so they need to be aggregated in some way.

. . .

```{r}
head(french_fries_long)

french_fries_long |>
    pivot_wider(id_cols = time,
                names_from = flavor,
                values_from = flavor_intensity)

```

-----

You can use the `values_fn` argument to `pivot_wider` to define how to aggregate values.
```{r}

french_fries_long |>
    pivot_wider(id_cols = time,
                names_from = flavor,
                values_from = flavor_intensity,
                values_fn = mean)

french_fries_long |>
    pivot_wider(names_from = flavor,
                id_cols = time,
                values_from = flavor_intensity,
                values_fn = function(x) mean(x))

french_fries_long |>
    pivot_wider(names_from = flavor,
                id_cols = time,
                values_from = flavor_intensity,
                values_fn = function(x) mean(x, na.rm = TRUE))
```

The `tidyverse` functions also have shortcut notation for defining anonymous functions.
See [here](https://adv-r.hadley.nz/functionals.html?q=lambda%20function#purrr-shortcuts) for details.
It works best for functions that have one or two arguments, which are referred to as `.x` (first/only argument) and `.y` (second argument in a two-argument function).
```{r}
## "shortcut" version
french_fries_long |>
    pivot_wider(names_from = flavor,
                id_cols = time,
                values_from = flavor_intensity,
                values_fn = ~mean(.x, na.rm = TRUE))
```



## Merging 

Final topic: What if you have data from two different places and you
need to put them together?

Base R syntax: `merge(x, y, by.x, by.y)`

- `x` and `y` are the two datasets you want to merge.

- `by.x` is the column of `x` to merge on.

- `by.y` is the column of `y` to merge on.

dpylr syntax: `*_join(x, y, by = c("x_col" = "y_col"))`

- `*_join` can be any of `left_join`, `right_join`, `inner_join`, `full_join` for different types of merges.

- `by` argument is a character vector specifying the columns to join on.

- Defaults to matching all columns with the same name.

-----

Example:

```{r}
cities <- data.frame(
    city=c('New York','Boston','Juneau',
           'Anchorage','San Diego',
           'Philadelphia','Los Angeles',
           'Fairbanks','Ann Arbor','Seattle'),
    state.abb=c('NY','MA','AK','AK','CA',
                'PA','CA','AK','MI','WA'))

states <- data.frame(state.name, state.abb)
cities
head(states)
```


We want to add the state name to the cities data frame, and we can use merge.



```{r}
library(dplyr)
## base R
merge(states, cities, by.x = "state.abb", by.y = "state.abb")
## dplyr
inner_join(states, cities, by = "state.abb")
```

-----

Notice in the last example that there was some ambiguity in how the
merge took place because the two datasets have different sets of
values for `state.abb`.

- In base R, the default is an inner join (you get one row for each value of the merging variable that was seen in both `x` and `y`)

- Modify with `all`, `all.x`, `all.y`:

- `all = TRUE` is a full outer join (you get one row for values of the merging
variable that were seen in either `x` or `y`)

- `all.x = TRUE` is a left join (you get one row for each value of the merging
variable that was seen in `x`)

- `all.y = TRUE` is a right join (you get one row for each value of the merging
variable that was seen in `y`)

- In dplyr, you use `inner_join`, `outer_join`, `left_join`, `right_join`

-----

```{r}
merge(states, cities, all.x = TRUE)
left_join(states, cities, by = "state.abb")

merge(states, cities, all.y = TRUE)
right_join(states, cities, by = "state.abb")

merge(states, cities, all = TRUE)
full_join(states, cities, by = "state.abb")
```
-----


Some additional notes:

- Default if you don't specify `by.x` and `by.y` is to use the columns
that are common to the two.

- `by.x`/`by.y` can have length more than 1, in which case we match
on the entire set of specified variables.

- Can use `by` instead of `by.x` and `by.y`, in which case the name of
the column to merge on has to be the same in both `x` and `y`.

---

```{r}
cities <- data.frame(
  city = c("New York", "Boston", "Juneau", "Anchorage", "San Diego"),
  state.abb = c("NY", "MA", "AK", "AK", "CA"),
  year = c(2020, 2020, 2021, 2021, 2020)
)


population <- data.frame(
  abb = c("NY", "MA", "AK", "AK", "CA"),
  year = c(2020, 2020, 2021, 2020, 2020),
  pop_million = c(19.3, 6.9, 0.7, 0.73, 39.5)
)

cities
population
```

Notice that `cities` and `population` have different names for the column giving the state abbreviation.

Below we see an example of merging on two columns in base R and in dplyr when the column names are not the same in the two datasets.
```{r}
merge(cities, population, by.x = c("state.abb", "year"), by.y = c("abb", "year"))
inner_join(cities, population, by = c("state.abb" = "abb", "year" = "year"))
```
