<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Julia Fukuyama" />
  <title>Stat 470/670 Lecture 23: Count responses and Poisson regression</title>
  <style type="text/css">
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="https://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <script src="https://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Stat 470/670 Lecture 23: Count responses and Poisson
regression</h1>
  <p class="author">
Julia Fukuyama
  </p>
</div>
<div id="stop-and-frisk-data" class="slide section level1">
<h1>Stop and frisk data</h1>
<p>Gelman and Hill have data on police stops in New York City in
1998–1999, during Giuliani’s mayoralty. There have been accusations that
some ethnic groups have been stopped at rates not justified by either
their arrest rate or their location (as measured by precinct.)</p>
<p>The data, with noise added for confidentiality, is at <a
href="http://www.stat.columbia.edu/~gelman/arm/examples/police/frisk_with_noise.dat">http://www.stat.columbia.edu/~gelman/arm/examples/police/frisk_with_noise.dat</a></p>
<p>The data gives counts of police stops for all combinations of</p>
<ul class="incremental">
<li><p><code>precinct</code>: 75 total</p></li>
<li><p><code>eth</code>: Ethnicity of the person stopped, three
possibilities (1 = Black, 2 = Hispanic, 3 = white), and</p></li>
<li><p><code>crime</code>: The type of crie, four possibilities (1 =
violent, 2 = weapons, 3 = property, and 4 = drug)</p></li>
</ul>
<p>This gives a total of <span class="math inline">\(75 \times 3 \times
4 = 900\)</span> rows.</p>
<p>There are two other variables in the data set:</p>
<ul class="incremental">
<li><p><code>pop</code>: population of the ethnic group within the
precinct, and</p></li>
<li><p><code>past.arrests</code>: the number of arrests of people in
that ethnic group in that precinct for that type of crime in
1997.</p></li>
</ul>
</div>
<div class="slide section level1">

<p>The first few rows of this file are a description, so we tell R to
skip these when reading the data.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>frisk <span class="ot">=</span> <span class="fu">read.table</span>(<span class="st">&quot;http://www.stat.columbia.edu/~gelman/arm/examples/police/frisk_with_noise.dat&quot;</span>, <span class="at">skip =</span> <span class="dv">6</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(frisk)</span></code></pre></div>
<pre><code>## [1] 900</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(frisk)</span></code></pre></div>
<pre><code>##      stops           pop          past.arrests       precinct       eth   
##  Min.   :   0   Min.   :   321   Min.   :   0.0   Min.   : 1   Min.   :1  
##  1st Qu.:  26   1st Qu.:  6844   1st Qu.:  53.0   1st Qu.:19   1st Qu.:1  
##  Median :  72   Median : 18004   Median : 124.0   Median :38   Median :2  
##  Mean   : 146   Mean   : 30105   Mean   : 262.8   Mean   :38   Mean   :2  
##  3rd Qu.: 173   3rd Qu.: 46669   3rd Qu.: 287.5   3rd Qu.:57   3rd Qu.:3  
##  Max.   :1755   Max.   :184345   Max.   :2655.0   Max.   :75   Max.   :3  
##      crime     
##  Min.   :1.00  
##  1st Qu.:1.75  
##  Median :2.50  
##  Mean   :2.50  
##  3rd Qu.:3.25  
##  Max.   :4.00</code></pre>
<p>Having numerical ethnicity is annoying, so recode:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>frisk<span class="sc">$</span>eth <span class="ot">=</span> <span class="fu">recode_factor</span>(frisk<span class="sc">$</span>eth, <span class="st">`</span><span class="at">1</span><span class="st">`</span> <span class="ot">=</span> <span class="st">&quot;Black&quot;</span>, <span class="st">`</span><span class="at">2</span><span class="st">`</span> <span class="ot">=</span> <span class="st">&quot;Hispanic&quot;</span>, <span class="st">`</span><span class="at">3</span><span class="st">`</span> <span class="ot">=</span> <span class="st">&quot;white&quot;</span>)</span></code></pre></div>
</div>
<div class="slide section level1">

<p>For the purposes of this lecture, we’ll ignore the type of crime, and
aggregate the number of stops and past arrests over all four types. If
you’re interested though, you should try a model that includes type of
crime as well and see if anything changes.</p>
<p>Aggregating in this way gives us 225 rows (75 precincts by three
ethnic groups):</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>frisk.sum <span class="ot">=</span> frisk <span class="sc">%&gt;%</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(precinct, eth) <span class="sc">%&gt;%</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarise</span>(<span class="at">stops =</span> <span class="fu">sum</span>(stops), <span class="at">past.arrests =</span> <span class="fu">sum</span>(past.arrests), <span class="at">pop =</span> <span class="fu">mean</span>(pop))</span></code></pre></div>
<pre><code>## `summarise()` has grouped output by &#39;precinct&#39;. You can override using the
## `.groups` argument.</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(frisk.sum)</span></code></pre></div>
<pre><code>## [1] 225</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(frisk.sum)</span></code></pre></div>
<pre><code>##     precinct        eth         stops         past.arrests       pop        
##  Min.   : 1   Black   :75   Min.   :   7.0   Min.   :  16   Min.   :   321  
##  1st Qu.:19   Hispanic:75   1st Qu.: 133.0   1st Qu.: 312   1st Qu.:  6844  
##  Median :38   white   :75   Median : 385.0   Median : 571   Median : 18004  
##  Mean   :38                 Mean   : 584.1   Mean   :1051   Mean   : 30105  
##  3rd Qu.:57                 3rd Qu.: 824.0   3rd Qu.:1467   3rd Qu.: 46669  
##  Max.   :75                 Max.   :2771.0   Max.   :5667   Max.   :184345</code></pre>
</div>
<div class="slide section level1">

<p>Let’s first draw some pictures.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(frisk.sum, <span class="fu">aes</span>(<span class="at">x =</span> stops, <span class="at">color =</span> eth, <span class="at">fill =</span> eth)) <span class="sc">+</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2800</span>, <span class="dv">50</span>)) <span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span>eth, <span class="at">ncol =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="lecture-23-fig/unnamed-chunk-4-1.png" /></p>
<p>Quite clearly, the distributions of stops for Black and Hispanic
people are very different from the distribution for white people, though
there may be multiple explanations for this.</p>
</div>
<div class="slide section level1">

<p>Let’s look at the relationship of stops with past arrests. Because of
skewness, we log both variables.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(frisk.sum, <span class="fu">aes</span>(<span class="at">x =</span> (past.arrests), <span class="at">y =</span> (stops), <span class="at">color =</span> eth)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="lecture-23-fig/unnamed-chunk-5-1.png" /></p>
<p>There’s certainly a relationship. The question is whether the
relationship between the two variables is sufficient to explain the
differences between the stops of the three ethnic groups. You could get
at this just by adding smoother for the three groups:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(frisk.sum, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">log</span>(past.arrests), <span class="at">y =</span> <span class="fu">log</span>(stops), <span class="at">group =</span> eth, <span class="at">color =</span> eth)) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">degree =</span> <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="lecture-23-fig/unnamed-chunk-6-1.png" /></p>
<p>Since this is an important topic, however, we should be a bit more
careful and construct a model.</p>
</div>
<div id="poisson-regression" class="slide section level1">
<h1>Poisson regression</h1>
<p>We’ll model this data using (at first) <em>Poisson regression</em>,
another form of generalized linear model.</p>
<p>Poisson regression is used instead of standard linear regression when
the response variable is a count (0, 1, 2, etc.) instead of a real
number.</p>
<p>You <em>could</em> use standard linear regression here (if you put
the numbers into <code>lm</code> in R it will give you results), but
Poisson regression can be better because counts tend to have a <a
href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson
distribution</a>, and Poisson distributed variables have a fixed
relationship between the mean and the variance.</p>
<p>If <span class="math inline">\(y \sim \text{Pois}(\lambda)\)</span>,
then <span class="math inline">\(E(y) = \lambda\)</span> and <span
class="math inline">\(\text{Var}(y) =\lambda\)</span>. This relationship
is inconsistent with the homoskedasticity assumptions of linear
regression.</p>
</div>
<div class="slide section level1">

<p>In a standard Poisson regression, the response has a Poisson
distribution with the <em>log</em> of the expected value given by a
linear function of the predictors.</p>
<p>In the single-variable case: <span class="math display">\[
\log(E[Y \mid x]) = \beta_0 + \beta_1 x
\]</span> and <span class="math display">\[
Y \sim \text{Pois}(E[Y \mid x])
\]</span></p>
</div>
<div class="slide section level1">

<p>We’ll start off with a Poission regression model that’s much too
simple, and build up to a more useful one.</p>
<p>The simplest model just treats each number of stops as a realization
of a Poisson random variable.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>constant.glm <span class="ot">=</span> <span class="fu">glm</span>(stops <span class="sc">~</span> <span class="dv">1</span>, <span class="at">family =</span> poisson, <span class="at">data =</span> frisk.sum)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(constant.glm)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = stops ~ 1, family = poisson, data = frisk.sum)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -33.049  -22.552   -8.788    9.343   65.227  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) 6.370053   0.002758    2309   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 123333  on 224  degrees of freedom
## Residual deviance: 123333  on 224  degrees of freedom
## AIC: 125041
## 
## Number of Fisher Scoring iterations: 5</code></pre>
</div>
<div class="slide section level1">

<p>By now you might be sick of all the cruft that gets displayed when we
use <code>summary()</code> on a GLM. Let’s use Gelman et al.’s
<code>display()</code> function in package <code>arm</code> instead.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;arm&quot;)</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arm)</span></code></pre></div>
<pre><code>## Error in library(arm): there is no package called &#39;arm&#39;</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(constant.glm)</span></code></pre></div>
<pre><code>## Error in display(constant.glm): could not find function &quot;display&quot;</code></pre>
<p>This pares away most of the low value information. We see the
coefficent estimate (on the log scale) is 6.37, which gives <span
class="math inline">\(e^{6.37} = 584\)</span> on the original scale.
That is, the number of stops for each ethnic group within each precinct
is modeled as a random variable with distribution</p>
<p><span class="math display">\[
\textrm{Poisson}(584).
\]</span></p>
<p>The other number to keep track of is the (residual)
<em>deviance</em>. Low deviance is good, as long as you’re not
overfitting. In particular, every time you add a degree of freedom, you
should expect to reduce the deviance by 1 if you’re just adding random
noise. So if you’re not overfitting when you fit a complex model, you
should expect to reduce the deviance by more than you increase the
degrees of freedom.</p>
</div>
<div class="slide section level1">

<p>Now this model is obviously inadequate. We might, for example, think
that the number of stops for an ethnic group in a precinct should be
proportional to the number of arrests for that ethnicity-precinct
(though this is controversial.) In a GLM, we can model this using an
<em>offset</em>:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>offset.glm <span class="ot">=</span> <span class="fu">glm</span>(stops <span class="sc">~</span> <span class="dv">1</span>, <span class="at">family =</span> poisson, <span class="at">offset =</span> <span class="fu">log</span>(past.arrests), <span class="at">data =</span> frisk.sum)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(offset.glm)</span></code></pre></div>
<pre><code>## Error in display(offset.glm): could not find function &quot;display&quot;</code></pre>
<p>Since the linear predictor is on the log scale, the offset also has
to be logged. This gives the following model for each precinct/race
combination:</p>
<p><span class="math display">\[
\log[E(\textrm{stops}|\textrm{past arrests})] = -0.59 +
\log(\textrm{past arrests})
\]</span> or (taking the exponential of both sides) <span
class="math display">\[
E(\textrm{stops}|\textrm{past arrests}) = e^{-0.59 + \log(\textrm{past
arrests})} = 0.56 \times \textrm{past arrests}
\]</span></p>
</div>
<div class="slide section level1">

<p>To check this, we look at the predicted number of stops for
precinct/race combinations with 10, 100, and 1000 past arrests
respectively:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(offset.glm,</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">past.arrests =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>)),</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 2
##   past.arrests .fitted
##          &lt;dbl&gt;   &lt;dbl&gt;
## 1           10    5.56
## 2          100   55.6 
## 3         1000  556.</code></pre>
<p>Our model has a much lower deviance than the constant model, so we’ve
improved the fit by a lot.</p>
</div>
<div class="slide section level1">

<p>Now we want to see what happens if we add ethnic group as a
predictor. Ethnic group is categorical, so we use it as a factor.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>eth.glm <span class="ot">=</span> <span class="fu">glm</span>(stops <span class="sc">~</span> eth, <span class="at">family =</span> poisson, <span class="at">offset =</span> <span class="fu">log</span>(past.arrests), <span class="at">data =</span> frisk.sum)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(eth.glm)</span></code></pre></div>
<pre><code>## Error in display(eth.glm): could not find function &quot;display&quot;</code></pre>
<p>Note that “past arrests” doesn’t have a coefficient: the model
assumes that expected stops are proportional to past arrests (where the
constant of proportionality may depend on other stuff.) The deviance has
dropped substantially again. On the log scale, we have additive terms
for the offset and for ethnicity (relative to Black, which is taken as
the baseline due to alphabetical order.) On the original scale, the
terms are multiplicative, and we can combine the offset and ethnicity
terms to get a coefficient for each ethnicity. That is, the model is
now</p>
<p><span class="math display">\[
\begin{align*}
E(\textrm{stops} | \textrm{ethnic group, past arrests}) &amp;=
e^{\textrm{intercept} + \textrm{ethnicity coefficient} +
\textrm{log}(\textrm{past arrests})}\\
&amp;=  \textrm{multiplier for ethnic group} \times \textrm{past
arrests}
\end{align*}
\]</span></p>
<p>where the multipliers are</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>eth.co <span class="ot">=</span> <span class="fu">coefficients</span>(eth.glm)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>multipliers <span class="ot">=</span> <span class="fu">exp</span>(<span class="fu">c</span>(eth.co[<span class="dv">1</span>], eth.co[<span class="dv">1</span>] <span class="sc">+</span> eth.co[<span class="dv">2</span>], eth.co[<span class="dv">1</span>] <span class="sc">+</span> eth.co[<span class="dv">3</span>]))</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(multipliers)</span></code></pre></div>
<pre><code>## (Intercept) (Intercept) (Intercept) 
##   0.5553894   0.5957836   0.4725238</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>eth.coef <span class="ot">=</span> <span class="fu">tidy</span>(eth.glm)<span class="sc">$</span>estimate</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>multipliers <span class="ot">=</span> <span class="fu">exp</span>(<span class="fu">c</span>(eth.coef[<span class="dv">1</span>],</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    eth.coef[<span class="dv">1</span>] <span class="sc">+</span> eth.coef[<span class="dv">2</span>],</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    eth.coef[<span class="dv">1</span>] <span class="sc">+</span> eth.coef[<span class="dv">3</span>]))</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>multipliers</span></code></pre></div>
<pre><code>## [1] 0.5553894 0.5957836 0.4725238</code></pre>
<p>for Black, Hispanic, and white respectively. We can check this using
<code>augment()</code>:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(eth.glm,</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">past.arrests =</span> <span class="dv">1000</span>, <span class="at">eth =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;Hispanic&quot;</span>, <span class="st">&quot;white&quot;</span>)),</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   past.arrests eth      .fitted
##          &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;
## 1         1000 Black       555.
## 2         1000 Hispanic    596.
## 3         1000 white       473.</code></pre>
</div>
<div class="slide section level1">

<p>So far we have shown that Black and Hispanic people were stopped at a
proportionately higher fraction of their arrest rate compared to white
people.</p>
<p>However, as the data isn’t from a randomized experiment, there may be
confounding — it could be that Black and Hispanic people generally live
in precincts with higher stop rates. (Whether this is in itself evidence
of bias is again, controversial.)</p>
<p>Since this is exploratory work, we won’t attempt to prove
cause-and-effect, but we’ll see whether we can simply explain the
results by including a precinct variable. If we can, then the NYPD might
argue that minorities are only stopped more often because they, perhaps
coincidentally, tend to live in precincts with high stop rates.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>precinct.glm <span class="ot">=</span> <span class="fu">glm</span>(stops <span class="sc">~</span> eth <span class="sc">+</span> <span class="fu">factor</span>(precinct), <span class="at">family =</span> poisson, <span class="at">offset =</span> <span class="fu">log</span>(past.arrests), <span class="at">data =</span> frisk.sum)</span></code></pre></div>
<p>We won’t print out the full results because we now have a coefficient
for each precinct. Let’s just first check the deviance has gone down
significantly:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">deviance</span>(eth.glm)</span></code></pre></div>
<pre><code>## [1] 45437.35</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">deviance</span>(precinct.glm)</span></code></pre></div>
<pre><code>## [1] 3427.14</code></pre>
</div>
<div class="slide section level1">

<p>Now look at the first few coefficients (and their standard
errors):</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(precinct.glm)</span></code></pre></div>
<pre><code>## # A tibble: 77 × 5
##    term              estimate std.error statistic   p.value
##    &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1 (Intercept)        -1.38     0.0510     -27.0  7.21e-161
##  2 ethHispanic         0.0102   0.00680      1.50 1.34e-  1
##  3 ethwhite           -0.419    0.00943    -44.4  0        
##  4 factor(precinct)2  -0.149    0.0740      -2.01 4.41e-  2
##  5 factor(precinct)3   0.560    0.0568       9.87 5.87e- 23
##  6 factor(precinct)4   1.21     0.0575      21.0  3.03e- 98
##  7 factor(precinct)5   0.283    0.0568       4.98 6.34e-  7
##  8 factor(precinct)6   1.14     0.0580      19.7  1.72e- 86
##  9 factor(precinct)7   0.218    0.0643       3.39 6.96e-  4
## 10 factor(precinct)8  -0.391    0.0569      -6.87 6.51e- 12
## # … with 67 more rows</code></pre>
<p>After controlling for precinct, the differences between the white and
minority coefficients becomes even bigger.</p>
</div>
<div id="checking-the-model" class="slide section level1">
<h1>Checking the model</h1>
<p>As usual, our first plot for checking the model is to plot the
residuals against the fitted values and see what happens.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>precinct.glm.df <span class="ot">=</span> <span class="fu">augment</span>(precinct.glm, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>, <span class="at">type.residuals =</span> <span class="st">&quot;pearson&quot;</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(precinct.glm.df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">log</span>(.fitted), <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="at">span =</span> <span class="dv">1</span>, <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">degree =</span> <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="lecture-23-fig/unnamed-chunk-18-1.png" /></p>
<p>There’s some nonlinearity in the smoother, though the amount is
relatively small. If prediction was the goal, a nonparametric model
might provide an improvement.</p>
</div>
<div id="overdispersion" class="slide section level1">
<h1>Overdispersion</h1>
<p>If we care about more than just the conditional expectation, however,
we find a bigger problem. If the Poisson model were correct, the
standardized residuals should be on a similar scale to the standard
normal – that is, the vast majority should be within <span
class="math inline">\(\pm 2\)</span>. From the previous graph, that’s
clearly not the case.</p>
<p>We need to measure the <em>overdispersion</em> in the data. We could
do a formal <span class="math inline">\(\chi^2\)</span> test for
overdispersion, but instead, let’s calculate the typical size of the
squared residuals. (When we “average”, we divide the sum by the residual
degrees of freedom.) If the Poisson model is correct, this should be
close to 1. If it’s much more than 1, we need a better model.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>overdispersion <span class="ot">=</span> <span class="fu">sum</span>(precinct.glm.df<span class="sc">$</span>.resid<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="fu">df.residual</span>(precinct.glm)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>overdispersion</span></code></pre></div>
<pre><code>## [1] 21.88505</code></pre>
<p>This is much more than 1. In fact, this happens a lot with counts –
the data is often more dispersed than the Poisson model.</p>
</div>
<div id="how-bad-is-it" class="slide section level1">
<h1>How bad is it?</h1>
<p>We know there are problems with our model. But are they so bad that
we can’t draw conclusions from it?</p>
<p>One simple way of checking is to simulate a fake set of data, and see
if it closely resembles the actual set.</p>
<p>For a Poisson model, this is easy. We know according to the model,
each observation is a realization of a Poisson random variable, whose
parameter is given by the fitted value. Then we can use
<code>rpois()</code> to do simulation and do numerical summaries and
plots.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>precinct.fits <span class="ot">=</span> <span class="fu">augment</span>(precinct.glm, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>.fitted</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>sim1 <span class="ot">=</span> <span class="fu">rpois</span>(<span class="fu">nrow</span>(frisk.sum), <span class="at">lambda =</span> precinct.fits)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(frisk.sum<span class="sc">$</span>stops)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##     7.0   133.0   385.0   584.1   824.0  2771.0</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(sim1)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##     9.0   158.0   379.0   583.6   817.0  2728.0</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>sim.df <span class="ot">=</span> <span class="fu">data.frame</span>(frisk.sum, sim1)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>sim.long <span class="ot">=</span> sim.df <span class="sc">%&gt;%</span> <span class="fu">gather</span>(type, number, <span class="fu">c</span>(<span class="st">&quot;stops&quot;</span>, <span class="st">&quot;sim1&quot;</span>))</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sim.long, <span class="fu">aes</span>(<span class="at">x =</span> number)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2800</span>, <span class="dv">50</span>)) <span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span>type, <span class="at">ncol =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="lecture-23-fig/unnamed-chunk-20-1.png" /></p>
</div>
<div class="slide section level1">

<p>If we look at the histograms, there doesn’t seem to be much
difference. But what happens if we fit a model to the simulated data and
look at its residuals? We’ll find these and do a two-sample QQ plot of
them against the original residuals.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>precinct.sim <span class="ot">=</span> <span class="fu">glm</span>(sim1 <span class="sc">~</span> eth <span class="sc">+</span> <span class="fu">factor</span>(precinct), <span class="at">family =</span> poisson, <span class="at">offset =</span> <span class="fu">log</span>(past.arrests), <span class="at">data =</span> sim.df)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>resid.df <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">real.resid =</span> <span class="fu">augment</span>(precinct.glm, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>.resid,</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">sim.resid =</span> <span class="fu">augment</span>(precinct.sim, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>.resid)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(resid.df) <span class="sc">+</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">stat_qq</span>(<span class="fu">aes</span>(<span class="at">sample =</span> sim.resid),</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">distribution =</span> <span class="cf">function</span>(p) <span class="fu">quantile</span>(resid.df<span class="sc">$</span>real.resid, <span class="at">probs =</span> p)) <span class="sc">+</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">xlab</span>(<span class="st">&quot;real residual quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;simulation residual quantiles&quot;</span>)</span></code></pre></div>
<p><img src="lecture-23-fig/unnamed-chunk-21-1.png" /></p>
<p>If the model were correct, this QQ plot should be close to a line
through the origin with slope 1, and this is not. The real residuals are
much more spread out/have much larger variance than the residuals in the
simulation.</p>
<p>The simulation here is overkill, since we understand the Poisson
fairly well and already know the data is overdispersed. However, the
more complicated your model gets, the more useful this kind of
simulation is as a sanity check.</p>
</div>
<div id="fixing-overdispersion" class="slide section level1">
<h1>Fixing overdispersion</h1>
<p>The quickest fix is to use the quasipoisson family instead of the
Poisson.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>precinct.quasi <span class="ot">=</span> <span class="fu">glm</span>(stops <span class="sc">~</span> eth <span class="sc">+</span> <span class="fu">factor</span>(precinct), <span class="at">family =</span> quasipoisson, <span class="at">offset =</span> <span class="fu">log</span>(past.arrests), <span class="at">data =</span> frisk.sum)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(precinct.quasi)</span></code></pre></div>
<pre><code>## # A tibble: 77 × 5
##    term              estimate std.error statistic  p.value
##    &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept)        -1.38      0.239     -5.78  4.33e- 8
##  2 ethHispanic         0.0102    0.0318     0.320 7.49e- 1
##  3 ethwhite           -0.419     0.0441    -9.49  5.49e-17
##  4 factor(precinct)2  -0.149     0.346     -0.430 6.68e- 1
##  5 factor(precinct)3   0.560     0.266      2.11  3.66e- 2
##  6 factor(precinct)4   1.21      0.269      4.50  1.38e- 5
##  7 factor(precinct)5   0.283     0.266      1.06  2.89e- 1
##  8 factor(precinct)6   1.14      0.272      4.21  4.35e- 5
##  9 factor(precinct)7   0.218     0.301      0.725 4.70e- 1
## 10 factor(precinct)8  -0.391     0.266     -1.47  1.44e- 1
## # … with 67 more rows</code></pre>
<p>Note that the coefficients look the same as they were in the standard
Poisson case. However, their standard errors have been inflated by the
square root of their overdispersion. We can confirm that the fitted
values haven’t changed:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>precinct.fitted <span class="ot">=</span> <span class="fu">augment</span>(precinct.glm, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>.fitted</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>quasi.fitted <span class="ot">=</span> <span class="fu">augment</span>(precinct.quasi, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>.fitted</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(quasi.fitted <span class="sc">-</span> precinct.fitted)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       0       0       0       0       0       0</code></pre>
<p>So the quasipoission doesn’t change the fit, only the variance and
the standard errors.</p>
</div>
<div class="slide section level1">

<p>For interpretation, it may be useful to refit the model changing the
order of levels in <code>eth</code> to use whites as a baseline.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>frisk.sum.relev <span class="ot">=</span> frisk.sum <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">eth.releveled =</span> <span class="fu">factor</span>(eth, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;white&quot;</span>, <span class="st">&quot;Black&quot;</span>, <span class="st">&quot;Hispanic&quot;</span>)))</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>precinct.quasi2 <span class="ot">=</span> <span class="fu">glm</span>(stops <span class="sc">~</span> eth.releveled <span class="sc">+</span> <span class="fu">factor</span>(precinct),</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">family =</span> quasipoisson, <span class="at">offset =</span> <span class="fu">log</span>(past.arrests),</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> frisk.sum.relev)</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(precinct.quasi2)</span></code></pre></div>
<pre><code>## # A tibble: 77 × 5
##    term                  estimate std.error statistic  p.value
##    &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept)             -1.80     0.241     -7.46  6.81e-12
##  2 eth.releveledBlack       0.419    0.0441     9.49  5.49e-17
##  3 eth.releveledHispanic    0.429    0.0449     9.57  3.49e-17
##  4 factor(precinct)2       -0.149    0.346     -0.430 6.68e- 1
##  5 factor(precinct)3        0.560    0.266      2.11  3.66e- 2
##  6 factor(precinct)4        1.21     0.269      4.50  1.38e- 5
##  7 factor(precinct)5        0.283    0.266      1.06  2.89e- 1
##  8 factor(precinct)6        1.14     0.272      4.21  4.35e- 5
##  9 factor(precinct)7        0.218    0.301      0.725 4.70e- 1
## 10 factor(precinct)8       -0.391    0.266     -1.47  1.44e- 1
## # … with 67 more rows</code></pre>
</div>
<div class="slide section level1">

<p>We now back-transform to get intervals for the stop rates of Blacks
and Hispanics relative to whites, after adjusting for arrest rates and
precinct.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 and 3 are the rows corresponding to the Black and hispanic coefficients</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>eth.co <span class="ot">=</span> <span class="fu">tidy</span>(precinct.quasi2)[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>,]</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>eth.co<span class="sc">$</span>ethnicity <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;Hispanic&quot;</span>)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>eth.co.plotting <span class="ot">=</span> eth.co <span class="sc">%&gt;%</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">estimate_rescaled =</span> <span class="fu">exp</span>(estimate),</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">lower =</span> <span class="fu">exp</span>(estimate <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> std.error),</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>           <span class="at">upper =</span> <span class="fu">exp</span>(estimate <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> std.error))</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(eth.co.plotting) <span class="sc">+</span></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_pointrange</span>(<span class="fu">aes</span>(<span class="at">x =</span> ethnicity, <span class="at">y =</span> estimate_rescaled, <span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper)) <span class="sc">+</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylim</span>(<span class="dv">1</span>,<span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">1</span>, <span class="at">slope =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)<span class="sc">+</span></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylab</span>(<span class="st">&quot;Ratio of stop rate to that of whites,</span><span class="sc">\n</span><span class="st">adjusted for past arrests and precinct&quot;</span>) <span class="sc">+</span></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="st">&quot;Approximate 95% confidence intervals</span><span class="sc">\n</span><span class="st">for NYPD stop rates of minorities&quot;</span>) <span class="sc">+</span></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_flip</span>()</span></code></pre></div>
<p><img src="lecture-23-fig/unnamed-chunk-25-1.png" /></p>
<p>The confidence intervals don’t include 1. This would be consistent
with a hypothesis of bias against minorities, though we should think
very carefully about other confounding variables before drawing a firm
conclusion (e.g. type of crime, which we ignored.) You should check your
model very thoroughly. The statistics cannot give you a definitive
answer, but they can constrain what sorts of answers are consistent with
the data.</p>
</div>
<div id="other-fixes" class="slide section level1">
<h1>Other fixes</h1>
<p>There are lots of alternative approaches:</p>
<ul class="incremental">
<li>Negative binomial regression is an alternative to the quasipoisson
when the count data is overdispersed.</li>
<li>Nonparametric approaches like loess and GAM can give you a better
fit for the conditional expectation, at the cost of making inference
much more complicated.</li>
<li>A multilevel model has appeal here because of the large number of
precincts. It can deal with overdispersion as well as regularize the
estimates for the precincts. These get complicated very quickly
though..</li>
</ul>
</div>
</body>
</html>
