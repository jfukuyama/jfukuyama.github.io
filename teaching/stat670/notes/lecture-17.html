<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Julia Fukuyama" />
  <title>Stat 470/670 Lecture 17: Count responses and Poisson regression</title>
  <style type="text/css">
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="https://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <script src="https://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Stat 470/670 Lecture 17: Count responses and Poisson
regression</h1>
  <p class="author">
Julia Fukuyama
  </p>
</div>
<div id="today" class="slide section level1">
<h1>Today</h1>
<ul>
<li>Poisson regression: definition and examples</li>
</ul>
<ul>
<li>Offsets in Poisson regression: adding predictors whose coefficient
is constrained to be equal to 1</li>
</ul>
<ul>
<li>Deviance: the equivalent of residual sum of squares for Poisson
regression</li>
</ul>
<ul>
<li>Residuals: raw residuals are not as useful as they are in a linear
model.</li>
</ul>
</div>
<div id="motivating-example-stop-and-frisk-data"
class="slide section level1">
<h1>Motivating example: Stop and frisk data</h1>
<p>Gelman and Hill have data on police stops in New York City in
1998–1999, during Giuliani’s mayoralty. There have been accusations that
some ethnic groups have been stopped at rates not justified by either
their arrest rate or their location (as measured by precinct.)</p>
<p>The data, with noise added for confidentiality, is at <a
href="http://www.stat.columbia.edu/~gelman/arm/examples/police/frisk_with_noise.dat">http://www.stat.columbia.edu/~gelman/arm/examples/police/frisk_with_noise.dat</a></p>
<p>The data gives counts of police stops for all combinations of</p>
<ul>
<li><code>precinct</code>: 75 total</li>
</ul>
<ul>
<li><code>eth</code>: Ethnicity of the person stopped, three
possibilities (1 = Black, 2 = Hispanic, 3 = white), and</li>
</ul>
<ul>
<li><code>crime</code>: The type of crime, four possibilities (1 =
violent, 2 = weapons, 3 = property, and 4 = drug)</li>
</ul>
<p>This gives a total of <span class="math inline">\(75 \times 3 \times
4 = 900\)</span> rows.</p>
<p>There are two other variables in the data set:</p>
<ul>
<li><code>pop</code>: population of the ethnic group within the
precinct, and</li>
</ul>
<ul>
<li><code>past.arrests</code>: the number of arrests of people in that
ethnic group in that precinct for that type of crime in 1997.</li>
</ul>
</div>
<div class="slide section level1">

<p>The first few rows of this file are a description, so we tell R to
skip these when reading the data.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>frisk <span class="ot">=</span> <span class="fu">read.table</span>(<span class="st">&quot;frisk_with_noise.dat&quot;</span>, <span class="at">skip =</span> <span class="dv">6</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">nrow</span>(frisk)</span></code></pre></div>
<pre><code>## [1] 900</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">summary</span>(frisk)</span></code></pre></div>
<pre><code>##      stops           pop          past.arrests       precinct       eth   
##  Min.   :   0   Min.   :   321   Min.   :   0.0   Min.   : 1   Min.   :1  
##  1st Qu.:  26   1st Qu.:  6844   1st Qu.:  53.0   1st Qu.:19   1st Qu.:1  
##  Median :  72   Median : 18004   Median : 124.0   Median :38   Median :2  
##  Mean   : 146   Mean   : 30105   Mean   : 262.8   Mean   :38   Mean   :2  
##  3rd Qu.: 173   3rd Qu.: 46669   3rd Qu.: 287.5   3rd Qu.:57   3rd Qu.:3  
##  Max.   :1755   Max.   :184345   Max.   :2655.0   Max.   :75   Max.   :3  
##      crime     
##  Min.   :1.00  
##  1st Qu.:1.75  
##  Median :2.50  
##  Mean   :2.50  
##  3rd Qu.:3.25  
##  Max.   :4.00</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>frisk <span class="ot">=</span> <span class="fu">mutate</span>(frisk, <span class="at">eth =</span> <span class="fu">as.factor</span>(eth))</span></code></pre></div>
</div>
<div class="slide section level1">

<p>For the purposes of this lecture, we’ll ignore the type of crime, and
aggregate the number of stops and past arrests over all four types. If
you’re interested though, you should try a model that includes type of
crime as well and see if anything changes.</p>
<p>Aggregating in this way gives us 225 rows (75 precincts by three
ethnic groups):</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>frisk.sum <span class="ot">=</span> frisk <span class="sc">%&gt;%</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>    <span class="fu">group_by</span>(precinct, eth) <span class="sc">%&gt;%</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>    <span class="fu">summarise</span>(<span class="at">stops =</span> <span class="fu">sum</span>(stops), <span class="at">past.arrests =</span> <span class="fu">sum</span>(past.arrests), <span class="at">pop =</span> <span class="fu">mean</span>(pop))</span></code></pre></div>
<pre><code>## `summarise()` has grouped output by &#39;precinct&#39;. You can override using the
## `.groups` argument.</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">nrow</span>(frisk.sum)</span></code></pre></div>
<pre><code>## [1] 225</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">summary</span>(frisk.sum)</span></code></pre></div>
<pre><code>##     precinct  eth        stops         past.arrests       pop        
##  Min.   : 1   1:75   Min.   :   7.0   Min.   :  16   Min.   :   321  
##  1st Qu.:19   2:75   1st Qu.: 133.0   1st Qu.: 312   1st Qu.:  6844  
##  Median :38   3:75   Median : 385.0   Median : 571   Median : 18004  
##  Mean   :38          Mean   : 584.1   Mean   :1051   Mean   : 30105  
##  3rd Qu.:57          3rd Qu.: 824.0   3rd Qu.:1467   3rd Qu.: 46669  
##  Max.   :75          Max.   :2771.0   Max.   :5667   Max.   :184345</code></pre>
</div>
<div class="slide section level1">

<p>Let’s first draw some pictures.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">ggplot</span>(frisk.sum, <span class="fu">aes</span>(<span class="at">x =</span> stops, <span class="at">color =</span> eth, <span class="at">fill =</span> eth)) <span class="sc">+</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2800</span>, <span class="dv">50</span>)) <span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span> eth, <span class="at">ncol =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-3-1.png" /></p>
<p>Quite clearly, the distributions of stops for the three ethnicities
are different from each other. There are multiple potential explanations
of this phenomenon.</p>
</div>
<div class="slide section level1">

<p>Let’s look at the relationship of stops with past arrests. Because of
skewness, we log both variables.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">ggplot</span>(frisk.sum, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">log</span>(past.arrests), <span class="at">y =</span> <span class="fu">log</span>(stops), <span class="at">color =</span> eth)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-4-1.png" /></p>
<p>There’s certainly a relationship. The question is whether the
relationship between the two variables is sufficient to explain the
differences between the stops of the three ethnic groups. You could get
at this just by adding smoother for the three groups:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="fu">ggplot</span>(frisk.sum, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">log</span>(past.arrests), <span class="at">y =</span> <span class="fu">log</span>(stops), <span class="at">group =</span> eth, <span class="at">color =</span> eth)) <span class="sc">+</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">degree =</span> <span class="dv">1</span>), <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="lecture-17-fig/unnamed-chunk-5-1.png" /></p>
</div>
<div id="poisson-regression" class="slide section level1">
<h1>Poisson regression</h1>
<p>We’ll model this data using (at first) <em>Poisson regression</em>,
another form of generalized linear model.</p>
<p>Poisson regression is used instead of standard linear regression when
the response variable is a count (0, 1, 2, etc.) instead of a real
number.</p>
<p>You <em>could</em> use standard linear regression here (if you put
the numbers into <code>lm</code> in R it will give you results), but
Poisson regression can be better because counts tend to have a <a
href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson
distribution</a>, and Poisson distributed variables have a fixed
relationship between the mean and the variance.</p>
<p>If <span class="math inline">\(y \sim \text{Pois}(\lambda)\)</span>,
then <span class="math inline">\(E(y) = \lambda\)</span> and <span
class="math inline">\(\text{Var}(y) =\lambda\)</span>. This relationship
is inconsistent with the homoskedasticity assumptions of linear
regression.</p>
</div>
<div class="slide section level1">

<p>In a standard Poisson regression, the response has a Poisson
distribution with the <em>log</em> of the expected value given by a
linear function of the predictors.</p>
<p>In the single-variable case: <span class="math display">\[
\log(E[Y \mid x]) = \beta_0 + \beta_1 x
\]</span> and <span class="math display">\[
Y \sim \text{Pois}(E[Y \mid x])
\]</span></p>
<div class="incremental">
<p>If <span class="math inline">\(x\)</span> is instead a vector of
<span class="math inline">\(p\)</span> predictors and <span
class="math inline">\(\beta\)</span> is a vector of <span
class="math inline">\(p\)</span> coefficients, we have <span
class="math display">\[
\log(E[Y \mid x]) = \beta_0 + \beta^T x
\]</span> and <span class="math display">\[
Y \sim \text{Pois}(E[Y \mid x])
\]</span></p>
</div>
</div>
<div class="slide section level1">

<p>We’ll start off with a Poission regression model that’s much too
simple, and build up to a more useful one.</p>
<p>The simplest model just treats each number of stops as a realization
of a Poisson random variable.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>constant.glm <span class="ot">=</span> <span class="fu">glm</span>(stops <span class="sc">~</span> <span class="dv">1</span>, <span class="at">family =</span> poisson, <span class="at">data =</span> frisk.sum)</span></code></pre></div>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="co"># install.packages(&quot;arm&quot;)</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="fu">library</span>(arm)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a><span class="co"># display is like summary with a little bit less of the information you don&#39;t use very much</span></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="fu">display</span>(constant.glm)</span></code></pre></div>
<pre><code>## glm(formula = stops ~ 1, family = poisson, data = frisk.sum)
##             coef.est coef.se
## (Intercept) 6.37     0.00   
## ---
##   n = 225, k = 1
##   residual deviance = 123332.5, null deviance = 123332.5 (difference = 0.0)</code></pre>
<ul>
<li>The coefficent estimate (on the log scale) is 6.37,</li>
</ul>
<ul>
<li>Transforming to the original scale gives <span
class="math inline">\(e^{6.37} = 584\)</span>, that is, the number of
stops for each ethnic group within each precinct is modeled as a random
variable with distribution</li>
</ul>
<p><span class="math display">\[
\textrm{Poisson}(584).
\]</span></p>
<ul>
<li>The other number to keep track of is the (residual)
<em>deviance</em>. Low deviance is good, as long as you’re not
overfitting.</li>
</ul>
<ul>
<li>Every time you add a degree of freedom, you should expect to reduce
the deviance by 1 if you’re just adding random noise.</li>
</ul>
</div>
<div id="offsets" class="slide section level1">
<h1>Offsets</h1>
<p>One way this model is inadequate is that we might expect the number
of stops for an ethnic group in a precinct to be proportional to the
number of arrests for that ethnicity-precinct.</p>
<ul>
<li>In a GLM, we can model this using an <em>offset</em>.</li>
</ul>
<ul>
<li>An offset can be thought of as a predictor whose coefficient is
constrained to be equal to 1.</li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>offset.glm <span class="ot">=</span> <span class="fu">glm</span>(stops <span class="sc">~</span> <span class="dv">1</span>, <span class="at">family =</span> poisson, <span class="at">offset =</span> <span class="fu">log</span>(past.arrests), <span class="at">data =</span> frisk.sum)</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a><span class="fu">display</span>(offset.glm)</span></code></pre></div>
<pre><code>## glm(formula = stops ~ 1, family = poisson, data = frisk.sum, 
##     offset = log(past.arrests))
##             coef.est coef.se
## (Intercept) -0.59     0.00  
## ---
##   n = 225, k = 1
##   residual deviance = 46120.3, null deviance = 46120.3 (difference = 0.0)</code></pre>
<p>Since the linear predictor is on the log scale, the offset also has
to be logged. This gives the following model for each precinct/race
combination:</p>
<p><span class="math display">\[
\log[E(\textrm{stops}|\textrm{past arrests})] = -0.59 +
\log(\textrm{past arrests})
\]</span> or (taking the exponential of both sides) <span
class="math display">\[
E(\textrm{stops}|\textrm{past arrests}) = e^{-0.59 + \log(\textrm{past
arrests})} = 0.56 \times \textrm{past arrests}
\]</span></p>
</div>
<div class="slide section level1">

<p>To check this, we look at the predicted number of stops for
precinct/race combinations with 10, 100, and 1000 past arrests
respectively:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="fu">augment</span>(offset.glm,</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">past.arrests =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>)),</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>        <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 2
##   past.arrests .fitted
##          &lt;dbl&gt;   &lt;dbl&gt;
## 1           10    5.56
## 2          100   55.6 
## 3         1000  556.</code></pre>
<p>Our model has a much lower deviance than the constant model, so we’ve
improved the fit by a lot.</p>
</div>
<div class="slide section level1">

<p>Now we want to see what happens if we add ethnic group as a
predictor. Ethnic group is categorical, so we use it as a factor.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>eth.glm <span class="ot">=</span> <span class="fu">glm</span>(stops <span class="sc">~</span> eth, <span class="at">family =</span> poisson, <span class="at">offset =</span> <span class="fu">log</span>(past.arrests), <span class="at">data =</span> frisk.sum)</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a><span class="fu">display</span>(eth.glm)</span></code></pre></div>
<pre><code>## glm(formula = stops ~ eth, family = poisson, data = frisk.sum, 
##     offset = log(past.arrests))
##             coef.est coef.se
## (Intercept) -0.59     0.00  
## eth2         0.07     0.01  
## eth3        -0.16     0.01  
## ---
##   n = 225, k = 3
##   residual deviance = 45437.4, null deviance = 46120.3 (difference = 682.9)</code></pre>
<p>Notes:</p>
<ul>
<li>“Past arrests” doesn’t have a coefficient: the model assumes that
expected stops are proportional to past arrests.</li>
</ul>
<ul>
<li>The deviance has dropped substantially again.</li>
</ul>
<ul>
<li>On the log scale, we have additive terms for the offset and for
ethnicity (relative to eth = 1.</li>
</ul>
<ul>
<li>On the original scale, the terms are multiplicative, and we can
combine the offset and ethnicity terms to get a coefficient for each
ethnicity. That is, the model is now</li>
</ul>
<p><span class="math display">\[
\begin{align*}
E(\textrm{stops} | \textrm{ethnic group, past arrests}) &amp;=
e^{\textrm{intercept} + \textrm{ethnicity coefficient} +
\textrm{log}(\textrm{past arrests})}\\
&amp;=  \textrm{multiplier for ethnic group} \times \textrm{past
arrests}
\end{align*}
\]</span></p>
<p>where the multipliers are</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>eth.co <span class="ot">=</span> <span class="fu">coefficients</span>(eth.glm)</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>multipliers <span class="ot">=</span> <span class="fu">exp</span>(<span class="fu">c</span>(eth.co[<span class="dv">1</span>], eth.co[<span class="dv">1</span>] <span class="sc">+</span> eth.co[<span class="dv">2</span>], eth.co[<span class="dv">1</span>] <span class="sc">+</span> eth.co[<span class="dv">3</span>]))</span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a><span class="fu">print</span>(multipliers)</span></code></pre></div>
<pre><code>## (Intercept) (Intercept) (Intercept) 
##   0.5553894   0.5957836   0.4725238</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>eth.coef <span class="ot">=</span> <span class="fu">tidy</span>(eth.glm)<span class="sc">$</span>estimate</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>multipliers <span class="ot">=</span> <span class="fu">exp</span>(<span class="fu">c</span>(eth.coef[<span class="dv">1</span>],</span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>    eth.coef[<span class="dv">1</span>] <span class="sc">+</span> eth.coef[<span class="dv">2</span>],</span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a>    eth.coef[<span class="dv">1</span>] <span class="sc">+</span> eth.coef[<span class="dv">3</span>]))</span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a>multipliers</span></code></pre></div>
<pre><code>## [1] 0.5553894 0.5957836 0.4725238</code></pre>
<p>for eth = 1, 2, and 3 respectively. We can check this using
<code>augment()</code>:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="fu">augment</span>(eth.glm,</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">past.arrests =</span> <span class="dv">1000</span>, <span class="at">eth =</span> <span class="fu">c</span>(<span class="st">&quot;1&quot;</span>, <span class="st">&quot;2&quot;</span>, <span class="st">&quot;3&quot;</span>)),</span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a>        <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   past.arrests eth   .fitted
##          &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;
## 1         1000 1        555.
## 2         1000 2        596.
## 3         1000 3        473.</code></pre>
</div>
<div class="slide section level1">

<p>So far we have shown that eth 1 and 2 were stopped at a
proportionately higher fraction of their arrest rate compared to eth
3.</p>
<p>However, as the data isn’t from a randomized experiment, there may be
confounding — it could be that eth 1 and 2 generally live in precincts
with higher stop rates. (Whether this is in itself evidence of bias is
again, controversial.)</p>
<p>Since this is exploratory work, we won’t attempt to prove
cause-and-effect, but we’ll see whether we can simply explain the
results by including a precinct variable. If we can, then the NYPD might
argue that minorities are only stopped more often because they, perhaps
coincidentally, tend to live in precincts with high stop rates.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>precinct.glm <span class="ot">=</span> <span class="fu">glm</span>(stops <span class="sc">~</span> eth <span class="sc">+</span> <span class="fu">factor</span>(precinct), <span class="at">family =</span> poisson, <span class="at">offset =</span> <span class="fu">log</span>(past.arrests), <span class="at">data =</span> frisk.sum)</span></code></pre></div>
<p>We won’t print out the full results because we now have a coefficient
for each precinct. Let’s just first check the deviance has gone down
significantly:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a><span class="fu">deviance</span>(eth.glm)</span></code></pre></div>
<pre><code>## [1] 45437.35</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="fu">deviance</span>(precinct.glm)</span></code></pre></div>
<pre><code>## [1] 3427.14</code></pre>
</div>
<div class="slide section level1">

<p>Now look at the first few coefficients (and their standard
errors):</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a><span class="fu">tidy</span>(precinct.glm)</span></code></pre></div>
<pre><code>## # A tibble: 77 × 5
##    term              estimate std.error statistic   p.value
##    &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1 (Intercept)        -1.38     0.0510     -27.0  7.21e-161
##  2 eth2                0.0102   0.00680      1.50 1.34e-  1
##  3 eth3               -0.419    0.00943    -44.4  0        
##  4 factor(precinct)2  -0.149    0.0740      -2.01 4.41e-  2
##  5 factor(precinct)3   0.560    0.0568       9.87 5.87e- 23
##  6 factor(precinct)4   1.21     0.0575      21.0  3.03e- 98
##  7 factor(precinct)5   0.283    0.0568       4.98 6.34e-  7
##  8 factor(precinct)6   1.14     0.0580      19.7  1.72e- 86
##  9 factor(precinct)7   0.218    0.0643       3.39 6.96e-  4
## 10 factor(precinct)8  -0.391    0.0569      -6.87 6.51e- 12
## # ℹ 67 more rows</code></pre>
<p>After controlling for precinct, the differences between the
coefficients become even bigger.</p>
</div>
<div id="checking-the-model-residual-plots"
class="slide section level1">
<h1>Checking the model: Residual plots</h1>
<p>First try: make a residual vs. fitted plot as we have done for linear
models</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" tabindex="-1"></a>precinct.glm.df <span class="ot">=</span> <span class="fu">augment</span>(precinct.glm, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb38-2"><a href="#cb38-2" tabindex="-1"></a><span class="fu">ggplot</span>(precinct.glm.df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">log</span>(.fitted), <span class="at">y =</span> stops <span class="sc">-</span> .fitted)) <span class="sc">+</span></span>
<span id="cb38-3"><a href="#cb38-3" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb38-4"><a href="#cb38-4" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="at">span =</span> <span class="dv">1</span>, <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">degree =</span> <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="lecture-17-fig/unnamed-chunk-17-1.png" /></p>
<p>What do we see?</p>
</div>
<div id="pearson-residuals" class="slide section level1">
<h1>Pearson residuals</h1>
<ul>
<li>In the Poisson model, we assume that the response has a Poisson
distribution, and so we expect the raw residuals to be
heteroskedastic.</li>
</ul>
<ul>
<li>To see more subtle patterns, we divide the raw residuals by an
estimate of the standard deviation.</li>
</ul>
<ul>
<li>This is the “Pearson residual”: <span class="math display">\[
(y_i - \hat y_i) / \sqrt{\hat y_i}
\]</span> Numerator = residual and denominator = estimate of
variance</li>
</ul>
</div>
<div class="slide section level1">

<p>We can plot pearson residuals instead of raw residuals:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" tabindex="-1"></a>precinct.glm.df <span class="ot">=</span> <span class="fu">augment</span>(precinct.glm, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>, <span class="at">type.residuals =</span> <span class="st">&quot;pearson&quot;</span>)</span>
<span id="cb40-2"><a href="#cb40-2" tabindex="-1"></a><span class="fu">ggplot</span>(precinct.glm.df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">log</span>(.fitted), <span class="at">y =</span> .resid)) <span class="sc">+</span></span>
<span id="cb40-3"><a href="#cb40-3" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb40-4"><a href="#cb40-4" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="at">span =</span> <span class="dv">1</span>, <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">degree =</span> <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="lecture-17-fig/unnamed-chunk-18-1.png" /></p>
<p>There’s some nonlinearity in the smoother, though the amount is
relatively small. If prediction was the goal, a nonparametric model
might provide an improvement.</p>
</div>
<div id="overdispersion" class="slide section level1">
<h1>Overdispersion</h1>
<p>If we care about more than just the conditional expectation, however,
we find a bigger problem. If the Poisson model were correct, the
standardized residuals should be on a similar scale to the standard
normal – that is, the vast majority should be within <span
class="math inline">\(\pm 2\)</span>. From the previous graph, that’s
clearly not the case.</p>
<p>We need to measure the <em>overdispersion</em> in the data. We could
do a formal <span class="math inline">\(\chi^2\)</span> test for
overdispersion, but instead, let’s calculate the typical size of the
squared residuals. (When we “average”, we divide the sum by the residual
degrees of freedom.) If the Poisson model is correct, this should be
close to 1. If it’s much more than 1, we need a better model.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" tabindex="-1"></a>overdispersion <span class="ot">=</span> <span class="fu">sum</span>(precinct.glm.df<span class="sc">$</span>.resid<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="fu">df.residual</span>(precinct.glm)</span>
<span id="cb42-2"><a href="#cb42-2" tabindex="-1"></a>overdispersion</span></code></pre></div>
<pre><code>## [1] 21.88505</code></pre>
<p>This is much more than 1. In fact, this happens a lot with counts –
the data is often more dispersed than the Poisson model.</p>
</div>
<div id="how-bad-is-it" class="slide section level1">
<h1>How bad is it?</h1>
<p>We know there are problems with our model. But are they so bad that
we can’t draw conclusions from it?</p>
<p>Strategy:</p>
<ul>
<li>Simulate a fake set of data according to the fitted model, and see
if it closely resembles the actual set.</li>
</ul>
<ul>
<li>Extract the fitted values from the model.</li>
</ul>
<ul>
<li>For each fitted value, simulate a new value using a Poisson
distribution with the fitted value as the mean.</li>
</ul>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" tabindex="-1"></a>precinct.fits <span class="ot">=</span> <span class="fu">augment</span>(precinct.glm, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>.fitted</span>
<span id="cb44-2"><a href="#cb44-2" tabindex="-1"></a>sim1 <span class="ot">=</span> <span class="fu">rpois</span>(<span class="fu">nrow</span>(frisk.sum), <span class="at">lambda =</span> precinct.fits)</span>
<span id="cb44-3"><a href="#cb44-3" tabindex="-1"></a><span class="fu">summary</span>(frisk.sum<span class="sc">$</span>stops)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##     7.0   133.0   385.0   584.1   824.0  2771.0</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" tabindex="-1"></a><span class="fu">summary</span>(sim1)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##     9.0   158.0   379.0   583.6   817.0  2728.0</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" tabindex="-1"></a>sim.df <span class="ot">=</span> <span class="fu">data.frame</span>(frisk.sum, sim1)</span></code></pre></div>
</div>
<div id="do-the-marginal-distributions-match"
class="slide section level1">
<h1>Do the marginal distributions match?</h1>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb49-2"><a href="#cb49-2" tabindex="-1"></a>sim.long <span class="ot">=</span> sim.df <span class="sc">%&gt;%</span> <span class="fu">gather</span>(type, number, <span class="fu">c</span>(<span class="st">&quot;stops&quot;</span>, <span class="st">&quot;sim1&quot;</span>))</span>
<span id="cb49-3"><a href="#cb49-3" tabindex="-1"></a><span class="fu">ggplot</span>(sim.long, <span class="fu">aes</span>(<span class="at">x =</span> number)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2800</span>, <span class="dv">50</span>)) <span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span>type, <span class="at">ncol =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-21-1.png" /></p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" tabindex="-1"></a><span class="fu">ggplot</span>(sim.df) <span class="sc">+</span></span>
<span id="cb50-2"><a href="#cb50-2" tabindex="-1"></a>    <span class="fu">stat_qq</span>(<span class="fu">aes</span>(<span class="at">sample =</span> stops),</span>
<span id="cb50-3"><a href="#cb50-3" tabindex="-1"></a>            <span class="at">distribution =</span> <span class="cf">function</span>(p) <span class="fu">quantile</span>(sim.df<span class="sc">$</span>sim1, <span class="at">probs =</span> p))</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-21-2.png" /></p>
</div>
<div id="do-the-distributions-of-the-residuals-match"
class="slide section level1">
<h1>Do the distributions of the residuals match?</h1>
<p>Strategy:</p>
<ul>
<li>Fit the same model to the simulated data.</li>
</ul>
<ul>
<li>Extract the residuals from the model that used the simulated
data.</li>
</ul>
<ul>
<li>Make a QQ plot of the residuals in the model fit on simulated data
vs. the residuals in the model fit on the real data.</li>
</ul>
<ul>
<li>If the model is correct, the QQ plot should be close to a line
through the origin with slope 1.</li>
</ul>
</div>
<div class="slide section level1">

<p>Real residuals are much farther from the true values than the
simulated residuals.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" tabindex="-1"></a>precinct.sim <span class="ot">=</span> <span class="fu">glm</span>(sim1 <span class="sc">~</span> eth <span class="sc">+</span> <span class="fu">factor</span>(precinct), <span class="at">family =</span> poisson, <span class="at">offset =</span> <span class="fu">log</span>(past.arrests), <span class="at">data =</span> sim.df)</span>
<span id="cb51-2"><a href="#cb51-2" tabindex="-1"></a>resid.df <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">real.resid =</span> <span class="fu">augment</span>(precinct.glm, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>.resid,</span>
<span id="cb51-3"><a href="#cb51-3" tabindex="-1"></a>                      <span class="at">sim.resid =</span> <span class="fu">augment</span>(precinct.sim, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>.resid)</span>
<span id="cb51-4"><a href="#cb51-4" tabindex="-1"></a><span class="fu">ggplot</span>(resid.df) <span class="sc">+</span></span>
<span id="cb51-5"><a href="#cb51-5" tabindex="-1"></a>    <span class="fu">stat_qq</span>(<span class="fu">aes</span>(<span class="at">sample =</span> sim.resid),</span>
<span id="cb51-6"><a href="#cb51-6" tabindex="-1"></a>            <span class="at">distribution =</span> <span class="cf">function</span>(p) <span class="fu">quantile</span>(resid.df<span class="sc">$</span>real.resid, <span class="at">probs =</span> p)) <span class="sc">+</span></span>
<span id="cb51-7"><a href="#cb51-7" tabindex="-1"></a>        <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb51-8"><a href="#cb51-8" tabindex="-1"></a>        <span class="fu">xlab</span>(<span class="st">&quot;real residual quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;simulation residual quantiles&quot;</span>)</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-22-1.png" /></p>
</div>
<div id="fixing-overdispersion" class="slide section level1">
<h1>Fixing overdispersion</h1>
<ul>
<li>Use the quasipoisson family instead of the Poisson.</li>
</ul>
<ul>
<li>Coefficients will be the same, only thing that changes are standard
errors.</li>
</ul>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" tabindex="-1"></a>precinct.quasi <span class="ot">=</span> <span class="fu">glm</span>(stops <span class="sc">~</span> eth <span class="sc">+</span> <span class="fu">factor</span>(precinct), <span class="at">family =</span> quasipoisson, <span class="at">offset =</span> <span class="fu">log</span>(past.arrests), <span class="at">data =</span> frisk.sum)</span>
<span id="cb52-2"><a href="#cb52-2" tabindex="-1"></a><span class="fu">tidy</span>(precinct.quasi)</span></code></pre></div>
<pre><code>## # A tibble: 77 × 5
##    term              estimate std.error statistic  p.value
##    &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept)        -1.38      0.239     -5.78  4.33e- 8
##  2 eth2                0.0102    0.0318     0.320 7.49e- 1
##  3 eth3               -0.419     0.0441    -9.49  5.49e-17
##  4 factor(precinct)2  -0.149     0.346     -0.430 6.68e- 1
##  5 factor(precinct)3   0.560     0.266      2.11  3.66e- 2
##  6 factor(precinct)4   1.21      0.269      4.50  1.38e- 5
##  7 factor(precinct)5   0.283     0.266      1.06  2.89e- 1
##  8 factor(precinct)6   1.14      0.272      4.21  4.35e- 5
##  9 factor(precinct)7   0.218     0.301      0.725 4.70e- 1
## 10 factor(precinct)8  -0.391     0.266     -1.47  1.44e- 1
## # ℹ 67 more rows</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" tabindex="-1"></a>precinct.fitted <span class="ot">=</span> <span class="fu">augment</span>(precinct.glm, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>.fitted</span>
<span id="cb54-2"><a href="#cb54-2" tabindex="-1"></a>quasi.fitted <span class="ot">=</span> <span class="fu">augment</span>(precinct.quasi, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>.fitted</span>
<span id="cb54-3"><a href="#cb54-3" tabindex="-1"></a><span class="fu">summary</span>(quasi.fitted <span class="sc">-</span> precinct.fitted)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       0       0       0       0       0       0</code></pre>
</div>
<div class="slide section level1">

<p>We now back-transform to get intervals for the stop rates by
ethnicity, after adjusting for arrest rates and precinct.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" tabindex="-1"></a><span class="do">## 2 and 3 are the rows corresponding to the eth = 2 and eth = 3 coefficients</span></span>
<span id="cb56-2"><a href="#cb56-2" tabindex="-1"></a>eth.co <span class="ot">=</span> <span class="fu">tidy</span>(precinct.quasi)[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>,]</span>
<span id="cb56-3"><a href="#cb56-3" tabindex="-1"></a>eth.co<span class="sc">$</span>ethnicity <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;2&quot;</span>, <span class="st">&quot;3&quot;</span>)</span>
<span id="cb56-4"><a href="#cb56-4" tabindex="-1"></a>eth.co.plotting <span class="ot">=</span> eth.co <span class="sc">%&gt;%</span></span>
<span id="cb56-5"><a href="#cb56-5" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">estimate_rescaled =</span> <span class="fu">exp</span>(estimate),</span>
<span id="cb56-6"><a href="#cb56-6" tabindex="-1"></a>           <span class="at">lower =</span> <span class="fu">exp</span>(estimate <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> std.error),</span>
<span id="cb56-7"><a href="#cb56-7" tabindex="-1"></a>           <span class="at">upper =</span> <span class="fu">exp</span>(estimate <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> std.error))</span>
<span id="cb56-8"><a href="#cb56-8" tabindex="-1"></a><span class="fu">ggplot</span>(eth.co.plotting) <span class="sc">+</span></span>
<span id="cb56-9"><a href="#cb56-9" tabindex="-1"></a>    <span class="fu">geom_pointrange</span>(<span class="fu">aes</span>(<span class="at">x =</span> ethnicity, <span class="at">y =</span> estimate_rescaled, <span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper)) <span class="sc">+</span></span>
<span id="cb56-10"><a href="#cb56-10" tabindex="-1"></a>    <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">1</span>, <span class="at">slope =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)<span class="sc">+</span></span>
<span id="cb56-11"><a href="#cb56-11" tabindex="-1"></a>    <span class="fu">ylab</span>(<span class="st">&quot;Ratio of stop rate relative to Blacks,</span><span class="sc">\n</span><span class="st">adjusted for past arrests and precinct&quot;</span>) <span class="sc">+</span></span>
<span id="cb56-12"><a href="#cb56-12" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="st">&quot;Approximate 95% confidence intervals</span><span class="sc">\n</span><span class="st">for NYPD stop rates of minorities&quot;</span>) <span class="sc">+</span></span>
<span id="cb56-13"><a href="#cb56-13" tabindex="-1"></a>    <span class="fu">coord_flip</span>()</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-25-1.png" /></p>
<p>The confidence interval for comparing to whites doesn’t include 1.
This would be consistent with a hypothesis of bias against minorities,
though we should think very carefully about other confounding variables
before drawing a firm conclusion (e.g. type of crime, which we ignored.)
The statistics cannot give you a definitive answer, but they can
constrain what sorts of answers are consistent with the data.</p>
</div>
<div id="other-fixes-for-overdispersion-in-poisson-models"
class="slide section level1">
<h1>Other fixes for overdispersion in Poisson models</h1>
<p>There are lots of alternative approaches:</p>
<ul>
<li>Negative binomial regression is an alternative to the quasipoisson
when the count data is overdispersed.</li>
<li>Nonparametric approaches like loess and GAM can give you a better
fit for the conditional expectation, at the cost of making inference
much more complicated.</li>
<li>A multilevel model has appeal here because of the large number of
precincts. It can deal with overdispersion as well as regularize the
estimates for the precincts. These get complicated very quickly
though..</li>
</ul>
</div>
<div id="overall" class="slide section level1">
<h1>Overall</h1>
<ul>
<li>We saw Poisson regression and how/why to include offsets in a
Poisson regression model.</li>
</ul>
<ul>
<li>We saw how to compare models using residual deviance.</li>
</ul>
<ul>
<li>We saw why we need to use Pearson residuals instead of raw
residuals.</li>
</ul>
</div>
</body>
</html>
