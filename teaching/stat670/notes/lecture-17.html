<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Julia Fukuyama" />
  <meta name="date" content="2021-03-18" />
  <title>Stat 470/670 Lecture 17: Multi-Dimensional Scaling</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="https://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <script src="https://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Stat 470/670 Lecture 17: Multi-Dimensional Scaling</h1>
  <p class="author">
Julia Fukuyama
  </p>
  <p class="date">March 18, 2021</p>
</div>
<div class="slide section level2">

<pre><code>## Loading required package: permute</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## This is vegan 2.5-6</code></pre>
<pre><code>## News at https://www.r4photobiology.info/</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✔ tibble  3.1.0     ✔ dplyr   1.0.2
## ✔ tidyr   1.1.0     ✔ stringr 1.4.0
## ✔ readr   1.3.1     ✔ forcats 0.5.0
## ✔ purrr   0.3.4</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ tidyr::extract()   masks magrittr::extract()
## ✖ dplyr::filter()    masks stats::filter()
## ✖ dplyr::lag()       masks stats::lag()
## ✖ purrr::set_names() masks magrittr::set_names()
## ✖ tidyr::spread()    masks photobiology::spread()</code></pre>
</div>
<div id="setup-for-multi-dimensional-scaling" class="slide section level2">
<h1>Setup for multi-dimensional scaling</h1>
<p>Instead of measurements on variables, like in PCA, we have distances between the samples.</p>
<p>The distances can be what was measured initially, or the distance could be constructed by the analyst from other variables that were measured directly.</p>
<p>In multi-dimensional scaling, the goal is to make a map of the samples in a low-dimensional space (probably 2-dimensional space) so that the distances in that map match the distances between the samples as closely as possible.</p>
</div>
<div id="some-examples-of-inputs-for-multi-dimensional-scaling" class="slide section level2">
<h1>Some examples of inputs for multi-dimensional scaling</h1>
<ul class="incremental">
<li><p>Subjective ratings of dissimilarities between objects</p></li>
<li><p>Distances between politicians based on voting records</p></li>
<li><p>Travel times between cities</p></li>
</ul>
</div>
<div id="fake-data-1" class="slide section level2">
<h1>Fake Data 1</h1>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a>D =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="kw">sqrt</span>(<span class="dv">2</span>),</span>
<span id="cb8-2"><a href="#cb8-2"></a>             <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>,</span>
<span id="cb8-3"><a href="#cb8-3"></a>             <span class="kw">sqrt</span>(<span class="dv">2</span>), <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb8-4"><a href="#cb8-4"></a>    <span class="dt">nrow =</span> <span class="dv">3</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)</span>
<span id="cb8-5"><a href="#cb8-5"></a><span class="kw">round</span>(D, <span class="dt">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,] 0.00    1 1.41
## [2,] 1.00    0 1.00
## [3,] 1.41    1 0.00</code></pre>
<p>Here <code>D</code> is a distance matrix, and the <span class="math inline">\((i,j)\)</span> element of <code>D</code> tells us the distance between sample <span class="math inline">\(i\)</span> and sample <span class="math inline">\(j\)</span>.</p>
<p>How would you position these samples in space so that the distances between them matched the distances in <code>D</code>?</p>
</div>
<div id="embedding-into-euclidean-space" class="slide section level2">
<h1>Embedding into Euclidean space</h1>
<p>In multi-dimensional scaling, we want to find an <em>embedding</em> of the samples into Euclidean space so that the distances between the embedded points match the distances between the samples as closely as possible.</p>
<p>This sounds fancy, but all it means is that we create a set of coordinates and assign each sample a value along each coordinate so that the distances between the samples match the input distances.</p>
</div>
<div class="slide section level2">

<p>How does this work on our fake data?</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">cmdscale</span>(D)</span></code></pre></div>
<pre><code>##               [,1]       [,2]
## [1,]  7.071068e-01  0.2357023
## [2,] -1.110223e-16 -0.4714045
## [3,] -7.071068e-01  0.2357023</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>mds_points =<span class="st"> </span><span class="kw">cmdscale</span>(D)</span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(mds_points)) <span class="op">+</span></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="st">    </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">x =</span> X1, <span class="dt">y =</span> X2, <span class="dt">label =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">coord_fixed</span>()</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-2-1.png" /></p>
</div>
<div class="slide section level2">

<p>We can check that the distances match:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="co">## The dist function computes distances (Euclidean</span></span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="co">## by default) between the rows of a data frame</span></span>
<span id="cb13-3"><a href="#cb13-3"></a><span class="kw">dist</span>(mds_points)</span></code></pre></div>
<pre><code>##          1        2
## 2 1.000000         
## 3 1.414214 1.000000</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a><span class="co">## compare with D, the input distances</span></span>
<span id="cb15-2"><a href="#cb15-2"></a>D</span></code></pre></div>
<pre><code>##          [,1] [,2]     [,3]
## [1,] 0.000000    1 1.414214
## [2,] 1.000000    0 1.000000
## [3,] 1.414214    1 0.000000</code></pre>
</div>
<div id="classical-multi-dimensional-scaling" class="slide section level2">
<h1>Classical Multi-Dimensional Scaling</h1>
<p>One solution to the multi-dimensional scaling problem is given by classical multi-dimensional scaling.</p>
<p>Let <span class="math inline">\(\mathbf D \in \mathbb R^{n \times n}\)</span> be a matrix where <span class="math inline">\(\mathbf D_{ij}\)</span> contains the square of the distance between sample <span class="math inline">\(i\)</span> and sample <span class="math inline">\(j\)</span>.</p>
<p>Let <span class="math inline">\(\mathbf H \in \mathbb R^{n \times n}\)</span> be the centering matrix, <span class="math inline">\(\mathbf H = \mathbf I - \frac{1}{n} \mathbf 1 \mathbf 1^T\)</span>.</p>
<p>Create the doubly-centered distance matrix <span class="math inline">\(\mathbf B = -\frac{1}{2} \mathbf H \mathbf D \mathbf H\)</span>, and let <span class="math inline">\(\mathbf U \mathbf \Lambda \mathbf U^T\)</span> be the singular value decomposition of <span class="math inline">\(\mathbf B\)</span>.</p>
<p>Then the <span class="math inline">\(k\)</span>-dimensional solution to the multi-dimensional scaling problem is obtained by taking <span class="math inline">\(\mathbf U_{(k)} \mathbf \Lambda_{(k)}^{1/2}\)</span>.</p>
</div>
<div class="slide section level2">

<p>Idea behind this solution:</p>
<p>Suppose the distance really did come from a matrix <span class="math inline">\(\mathbf X \in \mathbb R^{n \times k}\)</span>, where we computed the Euclidean distances between the rows of <span class="math inline">\(\mathbf X\)</span>. For definiteness, assume that the columns of <span class="math inline">\(\mathbf X\)</span> are centered.</p>
<p>Then it turns out (linear algebra exercise: verify this) that <span class="math inline">\((\mathbf H \mathbf X) (\mathbf H \mathbf X)^T = \mathbf B\)</span>.</p>
<p>The top <span class="math inline">\(k\)</span> left singular vectors of <span class="math inline">\(\mathbf X\)</span> (which is the same as <span class="math inline">\(\mathbf H \mathbf X\)</span> because <span class="math inline">\(\mathbf X\)</span> already has centered columns) will therefore give the optimal representation of the true embedded points that we got the distances from.</p>
<p>The singular vectors of <span class="math inline">\(\mathbf H \mathbf X\)</span> are the same as the singular vectors of <span class="math inline">\(\mathbf B\)</span>, so if we start off with <span class="math inline">\(\mathbf B\)</span> instead of <span class="math inline">\(\mathbf X\)</span>, we can still get the optimal low-dimensional embedding by taking the top singular vectors of <span class="math inline">\(\mathbf B\)</span>.</p>
</div>
<div id="checking-the-quality-of-the-mds-solution" class="slide section level2">
<h1>Checking the quality of the MDS solution</h1>
<p>Just as in PCA and with the SVD, we have a measure of the quality of the approximation.</p>
<p>In classical multi-dimensional scaling, these are given by the eigenvalues of <span class="math inline">\(\mathbf B\)</span>, and plotting the eigenvalues tells us how how much of the “variance” is explained by the multi-dimensional scaling axes.</p>
<p>If we can represent the distances perfectly with an embedding into <span class="math inline">\(k\)</span>-dimensional space, the top <span class="math inline">\(k\)</span> eigenvalues will be non-zero and the remainder will be zero.</p>
<p>We can check this on our fake data, where we constructed the distances so that they could be exactly represented in two-dimensional space.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a><span class="kw">cmdscale</span>(D, <span class="dt">eig =</span> <span class="ot">TRUE</span>)<span class="op">$</span>eig</span></code></pre></div>
<pre><code>## [1] 1.000000e+00 3.333333e-01 2.220446e-16</code></pre>
</div>
<div class="slide section level2">

<p>In general, you won’t be able to get an exact representation in a number of dimensions that’s easy to visualize, but you will want to know how well you’re doing with the number of dimensions you take.</p>
<p>We use the eigenvalues to make a scree plot, analogous to the PCA scree plot, to measure the quality of the embedding</p>
<p>Major difference between MDS and PCA:.</p>
<ul class="incremental">
<li><p>The eigenvalues can be negative.</p></li>
<li><p>Negative eigenvalues mean that there is no embedding of the points so that the Euclidean distances between them exactly match the input distances, and the size of the negative eigenvalues indicate how severe the problem is.</p></li>
<li><p>Not that important, but the terminology is that if you see negative eigenvalues, it means that your distances are <em>non-Euclidean</em>.</p></li>
</ul>
</div>
<div id="example-of-non-embeddable-set-of-points" class="slide section level2">
<h1>Example of non-embeddable set of points</h1>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a>D =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">.1</span>,</span>
<span id="cb19-2"><a href="#cb19-2"></a>             <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>,</span>
<span id="cb19-3"><a href="#cb19-3"></a>             <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">5</span>,</span>
<span id="cb19-4"><a href="#cb19-4"></a>             <span class="fl">.1</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">0</span>),</span>
<span id="cb19-5"><a href="#cb19-5"></a>    <span class="dt">nrow =</span> <span class="dv">4</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)</span>
<span id="cb19-6"><a href="#cb19-6"></a>D</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4]
## [1,]  0.0    1    1  0.1
## [2,]  1.0    0    1  5.0
## [3,]  1.0    1    0  5.0
## [4,]  0.1    5    5  0.0</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a>mds_points =<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">cmdscale</span>(D))</span>
<span id="cb21-2"><a href="#cb21-2"></a><span class="kw">dist</span>(mds_points)</span></code></pre></div>
<pre><code>##          1        2        3
## 2 2.436166                  
## 3 2.436166 1.000000         
## 4 2.605269 5.014562 5.014562</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a><span class="kw">ggplot</span>(mds_points) <span class="op">+</span></span>
<span id="cb23-2"><a href="#cb23-2"></a><span class="st">    </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">x =</span> X1, <span class="dt">y =</span> X2, <span class="dt">label =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">coord_fixed</span>()</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-5-1.png" /></p>
</div>
<div class="slide section level2">

<p>As promised, this shows up in negative eigenvalues:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1"></a>mds_eig =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">eig =</span> <span class="kw">cmdscale</span>(D, <span class="dt">eig =</span> <span class="ot">TRUE</span>)<span class="op">$</span>eig, <span class="dt">index =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>)</span>
<span id="cb24-2"><a href="#cb24-2"></a>mds_eig</span></code></pre></div>
<pre><code>##         eig index
## 1 16.987227     1
## 2  0.500000     2
## 3  0.000000     3
## 4 -4.234727     4</code></pre>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a><span class="kw">ggplot</span>(mds_eig) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> index, <span class="dt">y =</span> eig)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-6-1.png" /></p>
</div>
<div id="contrived-example-1-state-locations" class="slide section level2">
<h1>Contrived Example 1: State locations</h1>
<p>R contains data on state locations, including one called <code>state.center</code> that gives the latitude and longitude between</p>
<p>What happens if we compute distances between the centers of the states and run multi-dimensional scaling on those distances?</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a>state_locations =<span class="st"> </span><span class="kw">data.frame</span>(state.center)</span>
<span id="cb27-2"><a href="#cb27-2"></a>state_distances =<span class="st"> </span><span class="kw">dist</span>(state_locations, <span class="dt">method =</span> <span class="st">&quot;euclidean&quot;</span>)</span>
<span id="cb27-3"><a href="#cb27-3"></a>state_mds =<span class="st"> </span><span class="kw">cmdscale</span>(state_distances, <span class="dt">eig =</span> <span class="ot">TRUE</span>, <span class="dt">k =</span> <span class="dv">2</span>)</span></code></pre></div>
</div>
<div class="slide section level2">

<p>Before we get to the MDS plot, let’s look at the scree plot to see the quality of the MDS solution.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">eig =</span> state_mds<span class="op">$</span>eig, <span class="dt">index =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">50</span>)) <span class="op">+</span></span>
<span id="cb28-2"><a href="#cb28-2"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> index, <span class="dt">y =</span> eig)) <span class="op">+</span></span>
<span id="cb28-3"><a href="#cb28-3"></a><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&quot;Scree plot for MDS on distances between states&quot;</span>)</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-8-1.png" /></p>
<p>Why do we only get non-zero eigenvalues for the first two MDS axes?</p>
</div>
<div class="slide section level2">

<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(state_mds<span class="op">$</span>points), <span class="kw">aes</span>(<span class="dt">x =</span> X1, <span class="dt">y =</span> X2, <span class="dt">label =</span> state.name)) <span class="op">+</span></span>
<span id="cb29-2"><a href="#cb29-2"></a><span class="st">    </span><span class="kw">geom_text_repel</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">coord_fixed</span>()</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-9-1.png" /></p>
<p>When we plot the MDS solution, we get a map!</p>
<p>The states all have the correct relative locations, but the north-south axis is going the wrong way.</p>
<p>This is just due to an indeterminacy in the solution: the singular value decomposition is only determined up to a sign change for the singular vectors.</p>
<p>More heuristically, since we only provide MDS with distances, we can only expect it to give us good approximations to the distances between the samples, we can’t expect it to know about north and south.</p>
</div>
<div id="non-metric-mds" class="slide section level2">
<h1>Non-metric MDS</h1>
<p>Non-metric MDS is a robust alternative to classical MDS, and it is used when we want a map that preserves relative distances instead of absolute distances.</p>
<p>The idea is that we want to find a an embedding of the points into a lower-dimensional space so that the ranks of the distances are preserved as well as possible (the points that are the farthest from each other in the embedded space have the largest input distance, the points that are closest to each other in the embedded space have the smallest input distance, etc.).</p>
<p>To do this, we find an embedding of the points into a lower-dimensional space <em>and</em> a monotonic transformation of the embedded distances so that the transformed distances recapitulate the input distances as well as possible. The monotone transformation is essentially a trick that allows us to match ranks of distances instead of absolute distances.</p>
</div>
<div class="slide section level2">

<p>Notes:</p>
<ul class="incremental">
<li><p>NMDS is more resistant to outliers than classical MDS: if one point has a very large distance from all the others, the first classical MDS axis will tend to separate that point from the others and not be informative about the remaining distances.</p></li>
<li><p>Unlike classical MDS, NMDS does not give nested solutions: if we do NMDS with 2 axes, the first axis will not be equal to the NMDS solution with 1 axis.</p></li>
<li><p>There is no notion of percentage of variation explained by individual axes as in classical MDS.</p></li>
</ul>
</div>
<div id="implementation-of-nmds" class="slide section level2">
<h1>Implementation of NMDS</h1>
<p>Let <span class="math inline">\(d_i\)</span> contain the input distances, and let <span class="math inline">\(f\)</span> a monotone increasing function.</p>
<p>Note that since <span class="math inline">\(f\)</span> is monotone, <span class="math inline">\(d_i &lt; d_j\)</span> implies that <span class="math inline">\(f(d_i) &lt; f(d_j)\)</span>, and so the <em>relative</em> distances between the points are preserved under <span class="math inline">\(f\)</span>.</p>
<p>In NMDS, we want to minimize the stress function, defined as <span class="math display">\[
\text{STRESS}^2 = \frac{\sum_i (f(\tilde d_i) - d_i)^2}{\sum_j d_j^2}
\]</span> where <span class="math inline">\(d\)</span> represents the input distances, and <span class="math inline">\(\tilde d\)</span> represent the distances between the embedded points.</p>
<p>The NMDS algorithm is as follows:</p>
<ul class="incremental">
<li><p>Find a random embedding of the samples, e. g. by sampling from a normal distribution.</p></li>
<li><p>Calculate the distances <span class="math inline">\(\tilde d\)</span> between the embedded sample points.</p></li>
<li><p>Find the optimal monotonic transformation of the distances <span class="math inline">\(f\)</span> so that <span class="math inline">\(f(\tilde d)\)</span> matches <span class="math inline">\(d\)</span> as closely as possible.</p></li>
<li><p>Find the embedding of the samples such that the distances between the embedded points matches <span class="math inline">\(f(d)\)</span> as closely as possible.</p></li>
<li><p>Compare the stress to some criterion. If the change in stress is small enough then exit the algorithm, otherwise return to to step 2.</p></li>
</ul>
</div>
<div id="example-on-colors" class="slide section level2">
<h1>Example on colors</h1>
<p>In a psychology study (Ekman, Gosta. 1954. “Dimensions of Color Vision.” The Journal of Psychology 38 (2). Taylor &amp; Francis: 467–74.), the investigator asked subjects to rate similarities between colors.</p>
<p>These were combined to give overall measure of similarities between colors, and the results are in <code>ekman.txt</code>.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1"></a>ekm =<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;../../datasets/ekman.txt&quot;</span>, <span class="dt">header=</span><span class="ot">TRUE</span>)</span>
<span id="cb30-2"><a href="#cb30-2"></a><span class="kw">rownames</span>(ekm) =<span class="st"> </span><span class="kw">colnames</span>(ekm)</span>
<span id="cb30-3"><a href="#cb30-3"></a><span class="co">## the elements in ekm are similarities, but we</span></span>
<span id="cb30-4"><a href="#cb30-4"></a><span class="co">## need dissimilarities instead. We can create</span></span>
<span id="cb30-5"><a href="#cb30-5"></a><span class="co">## dissimilarities by taking the complement of</span></span>
<span id="cb30-6"><a href="#cb30-6"></a><span class="co">## the similarities and setting the diagonal to zero.</span></span>
<span id="cb30-7"><a href="#cb30-7"></a>ekm_dist =<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>ekm <span class="op">-</span><span class="st"> </span><span class="kw">diag</span>(<span class="dv">1</span>, <span class="kw">ncol</span>(ekm))</span>
<span id="cb30-8"><a href="#cb30-8"></a>ekm_dist[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>]</span></code></pre></div>
<pre><code>##      w434 w445 w465 w472 w490
## w434 0.00 0.14 0.58 0.58 0.82
## w445 0.14 0.00 0.50 0.56 0.78
## w465 0.58 0.50 0.00 0.19 0.53
## w472 0.58 0.56 0.19 0.00 0.46
## w490 0.82 0.78 0.53 0.46 0.00</code></pre>
</div>
<div class="slide section level2">

<p>Let’s try classical MDS first:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1"></a>ekm_mds =<span class="st"> </span><span class="kw">cmdscale</span>(ekm_dist, <span class="dt">eig =</span> <span class="ot">TRUE</span>)</span>
<span id="cb32-2"><a href="#cb32-2"></a><span class="co">## we can make a scree plot giving</span></span>
<span id="cb32-3"><a href="#cb32-3"></a><span class="co">## the fraction of variance explained</span></span>
<span id="cb32-4"><a href="#cb32-4"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">eig =</span> ekm_mds<span class="op">$</span>eig,</span>
<span id="cb32-5"><a href="#cb32-5"></a>                  <span class="dt">index =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(ekm_mds<span class="op">$</span>eig))) <span class="op">+</span></span>
<span id="cb32-6"><a href="#cb32-6"></a><span class="st">                      </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> index, <span class="dt">y =</span> eig))</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-11-1.png" /></p>
<p>Note that the negative eigenvalues at the end indicate that the dissimilarities cannot be exactly represented in Euclidean space, but the values are not that large and so we aren’t too concerned.</p>
<p>The top two eigenvalues are quite large, indicating that a two-dimensional MDS solution does a reasonable job at recapitulating the dissimilarities between the samples.</p>
</div>
<div class="slide section level2">

<p>And finally the plot:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1"></a><span class="co">## Here we&#39;re changing variable names and</span></span>
<span id="cb33-2"><a href="#cb33-2"></a><span class="co">## adding some additional information to</span></span>
<span id="cb33-3"><a href="#cb33-3"></a><span class="co">## the data frame we will use to plot the</span></span>
<span id="cb33-4"><a href="#cb33-4"></a><span class="co">## MDS solution</span></span>
<span id="cb33-5"><a href="#cb33-5"></a>ekm_points =<span class="st"> </span>ekm_mds<span class="op">$</span>points[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="op">%&gt;%</span></span>
<span id="cb33-6"><a href="#cb33-6"></a><span class="st">    </span>as_tibble <span class="op">%&gt;%</span></span>
<span id="cb33-7"><a href="#cb33-7"></a><span class="st">    </span><span class="kw">setNames</span>(<span class="kw">paste0</span>(<span class="st">&quot;MDS&quot;</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)) <span class="op">%&gt;%</span></span>
<span id="cb33-8"><a href="#cb33-8"></a><span class="st">    </span><span class="kw">mutate</span>(</span>
<span id="cb33-9"><a href="#cb33-9"></a>        <span class="dt">name =</span> <span class="kw">rownames</span>(ekm),</span>
<span id="cb33-10"><a href="#cb33-10"></a>        <span class="dt">rgb =</span> photobiology<span class="op">::</span><span class="kw">w_length2rgb</span>(<span class="kw">as.numeric</span>(<span class="kw">sub</span>(<span class="st">&quot;w&quot;</span>, <span class="st">&quot;&quot;</span>, name))))</span>
<span id="cb33-11"><a href="#cb33-11"></a><span class="kw">ggplot</span>(ekm_points, <span class="kw">aes</span>(<span class="dt">x =</span> MDS1, <span class="dt">y =</span> MDS2)) <span class="op">+</span></span>
<span id="cb33-12"><a href="#cb33-12"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">col =</span> ekm_points<span class="op">$</span>rgb, <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb33-13"><a href="#cb33-13"></a><span class="st">  </span><span class="kw">geom_text_repel</span>(<span class="kw">aes</span>(<span class="dt">label =</span> name)) <span class="op">+</span><span class="st"> </span><span class="kw">coord_fixed</span>()</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-12-1.png" /></p>
</div>
<div id="color-data-with-nmds" class="slide section level2">
<h1>Color data with NMDS</h1>
<p>Remember that NMDS is a randomized algorithm, so each run can in principle give a different solution.</p>
<p>The <code>metaMDS</code> function (in the package <code>vegan</code>) repeats the NMDS algorithm many times (20 by default) and looks for the best solution among the results.</p>
<p>The output here tells us that for each run of the algorithm, the stresses are about the same, suggesting that the corresponding solutions are the same.</p>
<p>The part of the output that says <code>Procrustes: rmse 1.060348e-06  max resid 1.960065e-06</code> is checking for similarity between the solutions directly: <code>rmse</code> and <code>max resid</code> describe the discrepancies between the solution and the previous best solution.</p>
<p>Here we see that the algorithm converges ot the same solution every time.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1"></a>ekm_nmds =<span class="st"> </span><span class="kw">metaMDS</span>(ekm_dist, <span class="dt">k =</span> <span class="dv">2</span>, <span class="dt">autotransform =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## Run 0 stress 0.02310251 
## Run 1 stress 0.02310251 
## ... Procrustes: rmse 2.102867e-06  max resid 3.320966e-06 
## ... Similar to previous best
## Run 2 stress 0.02310251 
## ... Procrustes: rmse 7.088863e-06  max resid 1.145484e-05 
## ... Similar to previous best
## Run 3 stress 0.02310251 
## ... Procrustes: rmse 6.438299e-06  max resid 1.040306e-05 
## ... Similar to previous best
## Run 4 stress 0.02310251 
## ... New best solution
## ... Procrustes: rmse 4.681247e-06  max resid 7.620905e-06 
## ... Similar to previous best
## Run 5 stress 0.02310251 
## ... New best solution
## ... Procrustes: rmse 3.633134e-06  max resid 6.162556e-06 
## ... Similar to previous best
## Run 6 stress 0.02310251 
## ... Procrustes: rmse 3.021893e-06  max resid 5.156862e-06 
## ... Similar to previous best
## Run 7 stress 0.02310251 
## ... New best solution
## ... Procrustes: rmse 1.146055e-06  max resid 2.470557e-06 
## ... Similar to previous best
## Run 8 stress 0.02310251 
## ... New best solution
## ... Procrustes: rmse 9.659437e-07  max resid 2.036998e-06 
## ... Similar to previous best
## Run 9 stress 0.02310251 
## ... Procrustes: rmse 4.787886e-06  max resid 8.130221e-06 
## ... Similar to previous best
## Run 10 stress 0.02310251 
## ... Procrustes: rmse 5.616317e-07  max resid 8.747772e-07 
## ... Similar to previous best
## Run 11 stress 0.02310251 
## ... Procrustes: rmse 5.527651e-07  max resid 1.104713e-06 
## ... Similar to previous best
## Run 12 stress 0.02310251 
## ... Procrustes: rmse 2.855771e-06  max resid 4.601952e-06 
## ... Similar to previous best
## Run 13 stress 0.02310251 
## ... Procrustes: rmse 1.506129e-06  max resid 2.440185e-06 
## ... Similar to previous best
## Run 14 stress 0.02310251 
## ... Procrustes: rmse 6.926222e-06  max resid 1.15127e-05 
## ... Similar to previous best
## Run 15 stress 0.02310251 
## ... Procrustes: rmse 8.158106e-07  max resid 1.29539e-06 
## ... Similar to previous best
## Run 16 stress 0.02310251 
## ... Procrustes: rmse 1.780811e-06  max resid 2.655272e-06 
## ... Similar to previous best
## Run 17 stress 0.02310251 
## ... Procrustes: rmse 6.859623e-07  max resid 1.288504e-06 
## ... Similar to previous best
## Run 18 stress 0.02310251 
## ... Procrustes: rmse 5.879151e-07  max resid 8.94391e-07 
## ... Similar to previous best
## Run 19 stress 0.02310251 
## ... Procrustes: rmse 4.007526e-06  max resid 6.695112e-06 
## ... Similar to previous best
## Run 20 stress 0.02310251 
## ... Procrustes: rmse 3.797161e-06  max resid 5.754955e-06 
## ... Similar to previous best
## *** Solution reached</code></pre>
</div>
<div class="slide section level2">

<p>We would like an analog of the scree plot so that we can evaluate how many dimensions to use.</p>
<p>One way to do this is to compute the stress function for each number of dimensions and plot that.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1"></a><span class="co">## since the algorithm is random, it would be</span></span>
<span id="cb36-2"><a href="#cb36-2"></a><span class="co">## better to do this many times for each value</span></span>
<span id="cb36-3"><a href="#cb36-3"></a><span class="co">## of k and take the average</span></span>
<span id="cb36-4"><a href="#cb36-4"></a>stresses =<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, <span class="cf">function</span>(k) <span class="kw">metaMDS</span>(ekm_dist, <span class="dt">k =</span> k, <span class="dt">autotransform =</span> <span class="ot">FALSE</span>)<span class="op">$</span>stress)</span></code></pre></div>
<pre><code>## Run 0 stress 0.2721258 
## Run 1 stress 0.5212407 
## Run 2 stress 0.4856468 
## Run 3 stress 0.490962 
## Run 4 stress 0.2567348 
## ... New best solution
## ... Procrustes: rmse 0.05564529  max resid 0.1384309 
## Run 5 stress 0.2687508 
## Run 6 stress 0.4533083 
## Run 7 stress 0.4373748 
## Run 8 stress 0.4843117 
## Run 9 stress 0.5071186 
## Run 10 stress 0.5291604 
## Run 11 stress 0.4866729 
## Run 12 stress 0.4983676 
## Run 13 stress 0.4942408 
## Run 14 stress 0.4915839 
## Run 15 stress 0.4584145 
## Run 16 stress 0.5006447 
## Run 17 stress 0.5165007 
## Run 18 stress 0.5246208 
## Run 19 stress 0.5003296 
## Run 20 stress 0.5081357 
## *** No convergence -- monoMDS stopping criteria:
##      1: stress ratio &gt; sratmax
##     19: scale factor of the gradient &lt; sfgrmin
## Run 0 stress 0.02310251 
## Run 1 stress 0.02310251 
## ... Procrustes: rmse 1.603649e-06  max resid 2.608348e-06 
## ... Similar to previous best
## Run 2 stress 0.02310251 
## ... New best solution
## ... Procrustes: rmse 1.283596e-06  max resid 2.203181e-06 
## ... Similar to previous best
## Run 3 stress 0.02310251 
## ... Procrustes: rmse 9.753636e-07  max resid 1.832654e-06 
## ... Similar to previous best
## Run 4 stress 0.2925031 
## Run 5 stress 0.02310251 
## ... Procrustes: rmse 5.337933e-06  max resid 8.633325e-06 
## ... Similar to previous best
## Run 6 stress 0.02310251 
## ... Procrustes: rmse 1.579965e-06  max resid 3.45673e-06 
## ... Similar to previous best
## Run 7 stress 0.02310251 
## ... Procrustes: rmse 3.284343e-06  max resid 5.161338e-06 
## ... Similar to previous best
## Run 8 stress 0.02310251 
## ... Procrustes: rmse 2.555243e-06  max resid 4.933159e-06 
## ... Similar to previous best
## Run 9 stress 0.02310251 
## ... New best solution
## ... Procrustes: rmse 1.01295e-06  max resid 2.103083e-06 
## ... Similar to previous best
## Run 10 stress 0.02310251 
## ... Procrustes: rmse 2.232036e-06  max resid 4.119736e-06 
## ... Similar to previous best
## Run 11 stress 0.02310251 
## ... Procrustes: rmse 1.663214e-06  max resid 3.072049e-06 
## ... Similar to previous best
## Run 12 stress 0.02310251 
## ... Procrustes: rmse 2.237823e-06  max resid 4.174616e-06 
## ... Similar to previous best
## Run 13 stress 0.02310251 
## ... New best solution
## ... Procrustes: rmse 1.327781e-06  max resid 2.668128e-06 
## ... Similar to previous best
## Run 14 stress 0.02310251 
## ... Procrustes: rmse 3.930095e-06  max resid 6.673939e-06 
## ... Similar to previous best
## Run 15 stress 0.02310251 
## ... Procrustes: rmse 1.227083e-06  max resid 2.181569e-06 
## ... Similar to previous best
## Run 16 stress 0.02310251 
## ... Procrustes: rmse 1.61893e-06  max resid 2.611836e-06 
## ... Similar to previous best
## Run 17 stress 0.02310251 
## ... Procrustes: rmse 4.812507e-06  max resid 7.680302e-06 
## ... Similar to previous best
## Run 18 stress 0.02310251 
## ... New best solution
## ... Procrustes: rmse 9.04642e-07  max resid 1.366657e-06 
## ... Similar to previous best
## Run 19 stress 0.02310251 
## ... Procrustes: rmse 2.685811e-06  max resid 5.192665e-06 
## ... Similar to previous best
## Run 20 stress 0.02310251 
## ... Procrustes: rmse 4.933418e-06  max resid 7.938065e-06 
## ... Similar to previous best
## *** Solution reached
## Run 0 stress 0.01253576 
## Run 1 stress 0.01703842 
## Run 2 stress 0.1085466 
## Run 3 stress 0.01715139 
## Run 4 stress 0.01483193 
## Run 5 stress 0.0156638 
## Run 6 stress 0.01253745 
## ... Procrustes: rmse 0.001812855  max resid 0.003286622 
## ... Similar to previous best
## Run 7 stress 0.01253767 
## ... Procrustes: rmse 0.001890592  max resid 0.003426268 
## ... Similar to previous best
## Run 8 stress 0.01678396 
## Run 9 stress 0.01715178 
## Run 10 stress 0.01529429 
## Run 11 stress 0.0152931 
## Run 12 stress 0.01253797 
## ... Procrustes: rmse 0.0005013934  max resid 0.0008736871 
## ... Similar to previous best
## Run 13 stress 0.01619717 
## Run 14 stress 0.01515287 
## Run 15 stress 0.01617234 
## Run 16 stress 0.012539 
## ... Procrustes: rmse 0.00219784  max resid 0.003643609 
## ... Similar to previous best
## Run 17 stress 0.01604329 
## Run 18 stress 0.01777524 
## Run 19 stress 0.01404241 
## Run 20 stress 0.01244572 
## ... New best solution
## ... Procrustes: rmse 0.01867244  max resid 0.04686828 
## *** No convergence -- monoMDS stopping criteria:
##      7: no. of iterations &gt;= maxit
##     13: stress ratio &gt; sratmax
## Run 0 stress 0.006273768 
## Run 1 stress 0.004990382 
## ... New best solution
## ... Procrustes: rmse 0.1007591  max resid 0.1849666 
## Run 2 stress 0.00487154 
## ... New best solution
## ... Procrustes: rmse 0.01068611  max resid 0.02011363 
## Run 3 stress 0.006313356 
## Run 4 stress 0.005815049 
## Run 5 stress 0.005724101 
## Run 6 stress 0.01109444 
## Run 7 stress 0.003030431 
## ... New best solution
## ... Procrustes: rmse 0.04301309  max resid 0.07967849 
## Run 8 stress 0.003766835 
## Run 9 stress 0.002812255 
## ... New best solution
## ... Procrustes: rmse 0.007655836  max resid 0.01192655 
## Run 10 stress 0.002872299 
## ... Procrustes: rmse 0.01055606  max resid 0.01956895 
## Run 11 stress 0.006120003 
## Run 12 stress 0.1316894 
## Run 13 stress 0.003452073 
## Run 14 stress 0.005912479 
## Run 15 stress 0.006849582 
## Run 16 stress 0.003751898 
## Run 17 stress 0.006483368 
## Run 18 stress 0.003709185 
## Run 19 stress 0.004488317 
## Run 20 stress 0.002733593 
## ... New best solution
## ... Procrustes: rmse 0.008442853  max resid 0.01632713 
## *** No convergence -- monoMDS stopping criteria:
##     19: no. of iterations &gt;= maxit
##      1: stress ratio &gt; sratmax
## Run 0 stress 0.0009367835 
## Run 1 stress 0.002131138 
## Run 2 stress 0.003907969 
## Run 3 stress 0.001706481 
## Run 4 stress 0.005466837 
## Run 5 stress 0.002919591 
## Run 6 stress 0.00258284 
## Run 7 stress 0.003337378 
## Run 8 stress 0.005895784 
## Run 9 stress 0.001076621 
## ... Procrustes: rmse 0.09829673  max resid 0.2129623 
## Run 10 stress 0.002311725 
## Run 11 stress 0.002533747 
## Run 12 stress 0.001741355 
## Run 13 stress 0.002134076 
## Run 14 stress 0.001557201 
## Run 15 stress 0.0006962816 
## ... New best solution
## ... Procrustes: rmse 0.08041192  max resid 0.1217456 
## Run 16 stress 0.001892428 
## Run 17 stress 0.002917626 
## Run 18 stress 0.001702046 
## Run 19 stress 0.002460906 
## Run 20 stress 0.002818138 
## *** No convergence -- monoMDS stopping criteria:
##     20: no. of iterations &gt;= maxit</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1"></a><span class="co">## note about above, autotransform is a parameter</span></span>
<span id="cb38-2"><a href="#cb38-2"></a><span class="co">## that is specific to ecology data, we want to</span></span>
<span id="cb38-3"><a href="#cb38-3"></a><span class="co">## set it to FALSE</span></span>
<span id="cb38-4"><a href="#cb38-4"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(stresses, <span class="dt">k =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> k, <span class="dt">y =</span> stresses))</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-14-1.png" /></p>
<p>Here we see that the stress drops substantially going from 1 to 2 dimensions, and then doesn’t go down that much once we increase the number of dimensions further.</p>
<p>This indicates to us that the two-dimensional solution is likely to be pretty good, just as it was with classical MDS.</p>
</div>
<div class="slide section level2">

<p>And the plot:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1"></a>nmds_points =<span class="st"> </span>ekm_nmds<span class="op">$</span>points[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="op">%&gt;%</span></span>
<span id="cb39-2"><a href="#cb39-2"></a><span class="st">    </span>as_tibble <span class="op">%&gt;%</span></span>
<span id="cb39-3"><a href="#cb39-3"></a><span class="st">    </span><span class="kw">setNames</span>(<span class="kw">paste0</span>(<span class="st">&quot;NMDS&quot;</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)) <span class="op">%&gt;%</span></span>
<span id="cb39-4"><a href="#cb39-4"></a><span class="st">    </span><span class="kw">bind_cols</span>(<span class="kw">select</span>(ekm_points, rgb, name))</span>
<span id="cb39-5"><a href="#cb39-5"></a><span class="kw">ggplot</span>(nmds_points, <span class="kw">aes</span>(<span class="dt">x =</span> NMDS1, <span class="dt">y =</span> NMDS2)) <span class="op">+</span></span>
<span id="cb39-6"><a href="#cb39-6"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">col =</span> ekm_points<span class="op">$</span>rgb, <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb39-7"><a href="#cb39-7"></a><span class="st">  </span><span class="kw">geom_text_repel</span>(<span class="kw">aes</span>(<span class="dt">label =</span> name)) <span class="op">+</span><span class="st"> </span><span class="kw">coord_fixed</span>()</span></code></pre></div>
<p><img src="lecture-17-fig/unnamed-chunk-15-1.png" /></p>
</div>
</body>
</html>
